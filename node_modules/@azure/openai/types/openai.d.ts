/** *
 * [Azure OpenAI](https://learn.microsoft.com/azure/cognitive-services/openai/overview)
 * provides REST API access to OpenAI's powerful language models including the GPT-3,
 * Codex and Embeddings model series. In addition, the new GPT-4 and ChatGPT (gpt-35-turbo)
 * model series have now reached general availability. These models can be easily adapted
 * to your specific task including but not limited to content generation, summarization,
 * semantic search, and natural language to code translation.
 *
 * @packageDocumentation
 */

import { AzureKeyCredential } from '@azure/core-auth';
import { ClientOptions } from '@azure-rest/core-client';
import { ErrorModel } from '@azure-rest/core-client';
import { KeyCredential } from '@azure/core-auth';
import { OperationOptions } from '@azure-rest/core-client';
import { TokenCredential } from '@azure/core-auth';

/** The type of the result of the transcription based on the requested response format */
export declare type AudioResult<ResponseFormat extends AudioResultFormat> = {
    json: AudioResultSimpleJson;
    verbose_json: AudioResultVerboseJson;
    vtt: string;
    srt: string;
    text: string;
}[ResponseFormat];

/** The result format of an audio task */
export declare type AudioResultFormat = "json"
/** This format will return an JSON structure containing an enriched structure with the transcription. */
| "verbose_json"
/** This will make the response return the transcription as plain/text. */
| "text"
/** The transcription will be provided in SRT format (SubRip Text) in the form of plain/text. */
| "srt"
/** The transcription will be provided in VTT format (Web Video Text Tracks) in the form of plain/text. */
| "vtt";

/** Simple transcription response */
export declare interface AudioResultSimpleJson {
    /** Transcribed text. */
    text: string;
}

/** Transcription response. */
export declare interface AudioResultVerboseJson extends AudioResultSimpleJson {
    /** Audio transcription task. */
    task: AudioTranscriptionTask;
    /** Language detected in the source audio file. */
    language: string;
    /** Duration. */
    duration: number;
    /** Segments. */
    segments: AudioSegment[];
}

/** Transcription segment. */
export declare interface AudioSegment {
    /** Segment identifier. */
    id: number;
    /** Segment start offset. */
    start: number;
    /** Segment end offset. */
    end: number;
    /** Segment text. */
    text: string;
    /** Temperature. */
    temperature: number;
    /** Average log probability. */
    avgLogprob: number;
    /** Compression ratio. */
    compressionRatio: number;
    /** Probability of 'no speech'. */
    noSpeechProb: number;
    /** Tokens in this segment */
    tokens: number[];
    /** TODO */
    seek: number;
}

/** Audio transcription task type */
/** "transcribe", "translate" */
export declare type AudioTranscriptionTask = string;

/** A representation of the available Azure OpenAI enhancement configurations. */
export declare interface AzureChatEnhancementConfiguration {
    /** A representation of the available options for the Azure OpenAI grounding enhancement. */
    grounding?: AzureChatGroundingEnhancementConfiguration;
    /** A representation of the available options for the Azure OpenAI optical character recognition (OCR) enhancement. */
    ocr?: AzureChatOCREnhancementConfiguration;
}

/**
 * Represents the output results of Azure enhancements to chat completions, as configured via the matching input provided
 * in the request.
 */
export declare interface AzureChatEnhancements {
    /** The grounding enhancement that returns the bounding box of the objects detected in the image. */
    grounding?: AzureGroundingEnhancement;
}

/**
 *   A representation of configuration data for a single Azure OpenAI chat extension. This will be used by a chat
 *   completions request that should use Azure OpenAI chat extensions to augment the response behavior.
 *   The use of this configuration is compatible only with Azure OpenAI.
 */
export declare type AzureChatExtensionConfiguration = AzureCognitiveSearchChatExtensionConfiguration | AzureMachineLearningIndexChatExtensionConfiguration | AzureCosmosDBChatExtensionConfiguration | ElasticsearchChatExtensionConfiguration | PineconeChatExtensionConfiguration;

/**
 *   A representation of the additional context information available when Azure OpenAI chat extensions are involved
 *   in the generation of a corresponding chat completions response. This context information is only populated when
 *   using an Azure OpenAI request configured to use a matching extension.
 */
export declare interface AzureChatExtensionsMessageContext {
    /**
     *   The contextual message payload associated with the Azure chat extensions used for a chat completions request.
     *   These messages describe the data source retrievals, plugin invocations, and other intermediate steps taken in the
     *   course of generating a chat completions response that was augmented by capabilities from Azure OpenAI chat
     *   extensions.
     */
    messages?: ChatResponseMessage[];
}

/**
 *   A representation of configuration data for a single Azure OpenAI chat extension. This will be used by a chat
 *   completions request that should use Azure OpenAI chat extensions to augment the response behavior.
 *   The use of this configuration is compatible only with Azure OpenAI.
 */
/** "AzureCognitiveSearch", "AzureMLIndex", "AzureCosmosDB", "Elasticsearch", "Pinecone" */
export declare type AzureChatExtensionType = string;

/** A representation of the available options for the Azure OpenAI grounding enhancement. */
export declare interface AzureChatGroundingEnhancementConfiguration {
    /** Specifies whether the enhancement is enabled. */
    enabled: boolean;
}

/** A representation of the available options for the Azure OpenAI optical character recognition (OCR) enhancement. */
export declare interface AzureChatOCREnhancementConfiguration {
    /** Specifies whether the enhancement is enabled. */
    enabled: boolean;
}

/**
 * A specific representation of configurable options for Azure Cognitive Search when using it as an Azure OpenAI chat
 * extension.
 */
export declare interface AzureCognitiveSearchChatExtensionConfiguration {
    /**
     * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its
     * default value for Azure Cognitive Search.
     */
    type: "AzureCognitiveSearch";
    /**
     * The authentication method to use when accessing the defined data source.
     * Each data source type supports a specific set of available authentication methods; please see the documentation of
     * the data source for supported mechanisms.
     * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
     * authentication.
     */
    authentication?: OnYourDataAuthenticationOptions;
    /** The configured top number of documents to feature for the configured query. */
    topNDocuments?: number;
    /** Whether queries should be restricted to use of indexed data. */
    inScope?: boolean;
    /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */
    strictness?: number;
    /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */
    roleInformation?: string;
    /** The absolute endpoint path for the Azure Cognitive Search resource to use. */
    endpoint: string;
    /** The name of the index to use as available in the referenced Azure Cognitive Search resource. */
    indexName: string;
    /** The API key to use when interacting with the Azure Cognitive Search resource. */
    key?: string;
    /** Customized field mapping behavior to use when interacting with the search index. */
    fieldsMapping?: AzureCognitiveSearchIndexFieldMappingOptions;
    /** The query type to use with Azure Cognitive Search. */
    queryType?: AzureCognitiveSearchQueryType;
    /** The additional semantic configuration for the query. */
    semanticConfiguration?: string;
    /** Search filter. */
    filter?: string;
    /** When using embeddings for search, specifies the resource endpoint URL from which embeddings should be retrieved. It should be in the format of format `https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/embeddings?api-version={api-version}`. */
    embeddingEndpoint?: string;
    /** When using embeddings, specifies the API key to use with the provided embeddings endpoint. */
    embeddingKey?: string;
    /** The embedding dependency for vector search. */
    embeddingDependency?: OnYourDataVectorizationSource;
}

/** Optional settings to control how fields are processed when using a configured Azure Cognitive Search resource. */
export declare interface AzureCognitiveSearchIndexFieldMappingOptions {
    /** The name of the index field to use as a title. */
    titleField?: string;
    /** The name of the index field to use as a URL. */
    urlField?: string;
    /** The name of the index field to use as a filepath. */
    filepathField?: string;
    /** The names of index fields that should be treated as content. */
    contentFields?: string[];
    /** The separator pattern that content fields should use. */
    contentFieldsSeparator?: string;
    /** The names of fields that represent vector data. */
    vectorFields?: string[];
    /** The names of fields that represent image vector data. */
    imageVectorFields?: string[];
}

/** The type of Azure Cognitive Search retrieval query that should be executed when using it as an Azure OpenAI chat extension. */
/** "simple", "semantic", "vector", "vectorSimpleHybrid", "vectorSemanticHybrid" */
export declare type AzureCognitiveSearchQueryType = "simple" | "semantic" | "vector" | "vectorSimpleHybrid" | "vectorSemanticHybrid";

/**
 * A specific representation of configurable options for Elasticsearch when using it as an Azure OpenAI chat
 * extension.
 */
export declare interface AzureCosmosDBChatExtensionConfiguration {
    /**
     * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its
     * default value for Azure Cosmos DB.
     */
    type: "AzureCosmosDB";
    /**
     * The authentication method to use when accessing the defined data source.
     * Each data source type supports a specific set of available authentication methods; please see the documentation of
     * the data source for supported mechanisms.
     * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
     * authentication.
     */
    authentication?: OnYourDataAuthenticationOptions;
    /** The configured top number of documents to feature for the configured query. */
    topNDocuments?: number;
    /** Whether queries should be restricted to use of indexed data. */
    inScope?: boolean;
    /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */
    strictness?: number;
    /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */
    roleInformation?: string;
    /** The MongoDB vCore database name to use with Azure Cosmos DB. */
    databaseName: string;
    /** The name of the Azure Cosmos DB resource container. */
    containerName: string;
    /** The MongoDB vCore index name to use with Azure Cosmos DB. */
    indexName: string;
    /** Customized field mapping behavior to use when interacting with the search index. */
    fieldsMapping: AzureCosmosDBFieldMappingOptions;
    /** The embedding dependency for vector search. */
    embeddingDependency?: OnYourDataVectorizationSource;
}

/** Optional settings to control how fields are processed when using a configured Azure Cosmos DB resource. */
export declare interface AzureCosmosDBFieldMappingOptions {
    /** The names of fields that represent vector data. */
    vectorFields: string[];
}

/**
 * Options for Azure OpenAI chat extensions.
 */
export declare interface AzureExtensionsOptions {
    /**
     *   The configuration entries for Azure OpenAI chat extensions that use them.
     *   This additional specification is only compatible with Azure OpenAI.
     */
    extensions?: AzureChatExtensionConfiguration[];
    /** If provided, the configuration options for available Azure OpenAI chat enhancements. */
    enhancements?: AzureChatEnhancementConfiguration;
}

/** The grounding enhancement that returns the bounding box of the objects detected in the image. */
export declare interface AzureGroundingEnhancement {
    /** The lines of text detected by the grounding enhancement. */
    lines: AzureGroundingEnhancementLine[];
}

/** A representation of a single polygon point as used by the Azure grounding enhancement. */
export declare interface AzureGroundingEnhancementCoordinatePoint {
    /** The x-coordinate (horizontal axis) of the point. */
    x: number;
    /** The y-coordinate (vertical axis) of the point. */
    y: number;
}

/** A content line object consisting of an adjacent sequence of content elements, such as words and selection marks. */
export declare interface AzureGroundingEnhancementLine {
    /** The text within the line. */
    text: string;
    /** An array of spans that represent detected objects and its bounding box information. */
    spans: AzureGroundingEnhancementLineSpan[];
}

/** A span object that represents a detected object and its bounding box information. */
export declare interface AzureGroundingEnhancementLineSpan {
    /** The text content of the span that represents the detected object. */
    text: string;
    /**
     * The character offset within the text where the span begins. This offset is defined as the position of the first
     * character of the span, counting from the start of the text as Unicode codepoints.
     */
    offset: number;
    /** The length of the span in characters, measured in Unicode codepoints. */
    length: number;
    /** An array of objects representing points in the polygon that encloses the detected object. */
    polygon: AzureGroundingEnhancementCoordinatePoint[];
}

export { AzureKeyCredential }

/**
 * A specific representation of configurable options for Azure Machine Learning vector index when using it as an Azure
 * OpenAI chat extension.
 */
export declare interface AzureMachineLearningIndexChatExtensionConfiguration {
    /**
     * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its
     * default value for Azure Machine Learning vector index.
     */
    type: "AzureMLIndex";
    /**
     * The authentication method to use when accessing the defined data source.
     * Each data source type supports a specific set of available authentication methods; please see the documentation of
     * the data source for supported mechanisms.
     * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
     * authentication.
     */
    authentication?: OnYourDataAuthenticationOptions;
    /** The configured top number of documents to feature for the configured query. */
    topNDocuments?: number;
    /** Whether queries should be restricted to use of indexed data. */
    inScope?: boolean;
    /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */
    strictness?: number;
    /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */
    roleInformation?: string;
    /** The resource ID of the Azure Machine Learning project. */
    projectResourceId: string;
    /** The Azure Machine Learning vector index name. */
    name: string;
    /** The version of the Azure Machine Learning vector index. */
    version: string;
    /** Search filter. Only supported if the Azure Machine Learning vector index is of type AzureSearch. */
    filter?: string;
}

/**
 * The representation of a single prompt completion as part of an overall chat completions request.
 * Generally, `n` choices are generated per provided prompt with a default value of 1.
 * Token limits and other settings may limit the number of choices generated.
 */
export declare interface ChatChoice {
    /** The chat message for a given chat completions prompt. */
    message?: ChatResponseMessage;
    /** The ordered index associated with this chat completions choice. */
    index: number;
    /** The reason that this chat completions choice completed its generated. */
    finishReason: CompletionsFinishReason | null;
    /**
     * The reason the model stopped generating tokens, together with any applicable details.
     * This structured representation replaces 'finishReason' for some models.
     */
    finishDetails?: ChatFinishDetails;
    /** The delta message content for a streaming response. */
    delta?: ChatResponseMessage;
    /**
     * Information about the content filtering category (hate, sexual, violence, selfHarm), if it
     * has been detected, as well as the severity level (very_low, low, medium, high-scale that
     * determines the intensity and risk level of harmful content) and if it has been filtered or not.
     */
    contentFilterResults?: ContentFilterResultsForChoice;
    /**
     * Represents the output results of Azure OpenAI enhancements to chat completions, as configured via the matching input
     * provided in the request. This supplementary information is only available when using Azure OpenAI and only when the
     * request is configured to use enhancements.
     */
    enhancements?: AzureChatEnhancements;
}

/**
 * Representation of the response data from a chat completions request.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
export declare interface ChatCompletions {
    /** A unique identifier associated with this chat completions response. */
    id: string;
    /**
     * The first timestamp associated with generation activity for this completions response,
     * represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
     */
    created: Date;
    /**
     * The collection of completions choices associated with this completions response.
     * Generally, `n` choices are generated per provided prompt with a default value of 1.
     * Token limits and other settings may limit the number of choices generated.
     */
    choices: ChatChoice[];
    /**
     * Content filtering results for zero or more prompts in the request. In a streaming request,
     * results for different prompts may arrive at different times or in different orders.
     */
    promptFilterResults: ContentFilterResultsForPrompt[];
    /**
     * Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that
     * might impact determinism.
     */
    systemFingerprint?: string;
    /** Usage information for tokens processed and generated as part of this completions operation. */
    usage?: CompletionsUsage;
}

/**
 * A tool call to a function tool, issued by the model in evaluation of a configured function tool, that represents
 * a function invocation needed for a subsequent chat completions request to resolve.
 */
export declare interface ChatCompletionsFunctionToolCall {
    /** The type of tool call, in this case always 'function'. */
    type: "function";
    /** The details of the function invocation requested by the tool call. */
    function: FunctionCall;
    /** The ID of the tool call. */
    id: string;
}

/** The definition information for a chat completions function tool that can call a function in response to a tool call. */
export declare interface ChatCompletionsFunctionToolDefinition {
    /** The object name, which is always 'function'. */
    type: "function";
    /** The function definition details for the function tool. */
    function: FunctionDefinition;
}

/** A response format for Chat Completions that restricts responses to emitting valid JSON objects.
 */
export declare interface ChatCompletionsJsonResponseFormat {
    /** The object type, which is always 'json_object' for this object. */
    type: "json_object";
}

/** A tool selection of a specific, named function tool that will limit chat completions to using the named function. */
export declare interface ChatCompletionsNamedFunctionToolSelection {
    /** The object type, which is always 'function'. */
    type: "function";
    /** Specifies a tool the model should use. Used to force the model to call a specific function. */
    function: {
        /** The name of the function that should be called. */
        name: string;
    };
}

/** A representation of an explicit, named tool selection to use for a chat completions request. */
export declare type ChatCompletionsNamedToolSelection = ChatCompletionsToolSelectionPreset | ChatCompletionsNamedFunctionToolSelection;

/** The valid response formats Chat Completions can provide. Used to enable JSON mode. */
export declare type ChatCompletionsResponseFormat = ChatCompletionsTextResponseFormat | ChatCompletionsJsonResponseFormat;

/** The standard Chat Completions response format that can freely generate text and is not guaranteed to produce response
 content that adheres to a specific schema. */
export declare interface ChatCompletionsTextResponseFormat {
    /** The object type, which is always 'text' for this object. */
    type: "text";
}

/**
 * A representation of a tool call that must be resolved in a subsequent request to perform the requested
 * chat completion.
 */
export declare type ChatCompletionsToolCall = ChatCompletionsFunctionToolCall;

/** A representation of a tool that can be used by the model to improve a chat completions response. */
export declare type ChatCompletionsToolDefinition = ChatCompletionsFunctionToolDefinition;

/** Represents a generic policy for how a chat completions tool may be selected. */
/** "auto", "none" */
export declare type ChatCompletionsToolSelectionPreset = "auto" | "none";

/** Structured information about why a chat completions response terminated. */
export declare type ChatFinishDetails = StopFinishDetails | MaxTokensFinishDetails;

/** A representation of a structured content item within a chat message. */
export declare type ChatMessageContentItem = ChatMessageTextContentItem | ChatMessageImageContentItem;

/** A structured chat content item containing an image reference. */
export declare interface ChatMessageImageContentItem {
    /** The discriminated object type: always 'image_url' for this type. */
    type: "image_url";
    /** An internet location, which must be accessible to the model,from which the image may be retrieved. */
    imageUrl: ChatMessageImageUrl;
}

/** A representation of the possible image detail levels for image-based chat completions message content. */
/** "auto", "low", "high" */
export declare type ChatMessageImageDetailLevel = "auto" | "low" | "high";

/** An internet location from which the model may retrieve an image. */
export declare interface ChatMessageImageUrl {
    /** The URL of the image. */
    url: string;
    /**
     * The evaluation quality setting to use, which controls relative prioritization of speed, token consumption, and
     * accuracy.
     *
     * Possible values: auto, low, high
     */
    detail?: ChatMessageImageDetailLevel;
}

/** A structured chat content item containing plain text. */
export declare interface ChatMessageTextContentItem {
    /** The discriminated object type: always 'text' for this type. */
    type: "text";
    /** The content of the message. */
    text: string;
}

/** A request chat message representing response or action from the assistant. */
export declare interface ChatRequestAssistantMessage {
    /** The chat role associated with this message, which is always 'assistant' for assistant messages. */
    role: "assistant";
    /** The content of the message. */
    content: string | null;
    /** An optional name for the participant. */
    name?: string;
    /**
     * The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
     * completions request to resolve as configured.
     */
    toolCalls?: Array<ChatCompletionsToolCall>;
    /**
     * The function call that must be resolved and have its output appended to subsequent input messages for the chat
     * completions request to resolve as configured.
     */
    functionCall?: FunctionCall;
}

/** A request chat message representing requested output from a configured function. */
export declare interface ChatRequestFunctionMessage {
    /** The chat role associated with this message, which is always 'function' for function messages. */
    role: "function";
    /** The name of the function that was called to produce output. */
    name: string;
    /** The output of the function as requested by the function call. */
    content: string | null;
}

/** An abstract representation of a chat message as provided in a request. */
export declare type ChatRequestMessage = ChatRequestSystemMessage | ChatRequestUserMessage | ChatRequestAssistantMessage | ChatRequestToolMessage | ChatRequestFunctionMessage;

/**
 * A request chat message containing system instructions that influence how the model will generate a chat completions
 * response.
 */
export declare interface ChatRequestSystemMessage {
    /** The chat role associated with this message, which is always 'system' for system messages. */
    role: "system";
    /** The contents of the system message. */
    content: string;
    /** An optional name for the participant. */
    name?: string;
}

/** A request chat message representing requested output from a configured tool. */
export declare interface ChatRequestToolMessage {
    /** The chat role associated with this message, which is always 'tool' for tool messages. */
    role: "tool";
    /** The content of the message. */
    content: string | null;
    /** The ID of the tool call resolved by the provided content. */
    toolCallId: string;
}

/** A request chat message representing user input to the assistant. */
export declare interface ChatRequestUserMessage {
    /** The chat role associated with this message, which is always 'user' for user messages. */
    role: "user";
    /** The contents of the user message, with available input types varying by selected model. */
    content: string | Array<ChatMessageContentItem>;
    /** An optional name for the participant. */
    name?: string;
}

/** A representation of a chat message as received in a response. */
export declare interface ChatResponseMessage {
    /** The chat role associated with the message. */
    role: ChatRole;
    /** The content of the message. */
    content: string | null;
    /**
     * The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
     * completions request to resolve as configured.
     */
    toolCalls: ChatCompletionsToolCall[];
    /**
     * The function call that must be resolved and have its output appended to subsequent input messages for the chat
     * completions request to resolve as configured.
     */
    functionCall?: FunctionCall;
    /**
     * If Azure OpenAI chat extensions are configured, this array represents the incremental steps performed by those
     * extensions while processing the chat completions request.
     */
    context?: AzureChatExtensionsMessageContext;
}

/** A description of the intended purpose of a message within a chat completions interaction. */
/** "system", "assistant", "user", "function", "tool" */
export declare type ChatRole = string;

/**
 * The representation of a single prompt completion as part of an overall completions request.
 * Generally, `n` choices are generated per provided prompt with a default value of 1.
 * Token limits and other settings may limit the number of choices generated.
 */
export declare interface Choice {
    /** The generated text for a given completions prompt. */
    text: string;
    /** The ordered index associated with this completions choice. */
    index: number;
    /**
     * Information about the content filtering category (hate, sexual, violence, selfHarm), if it
     * has been detected, as well as the severity level (very_low, low, medium, high-scale that
     * determines the intensity and risk level of harmful content) and if it has been filtered or not.
     */
    contentFilterResults?: ContentFilterResultsForChoice;
    /** The log probabilities model for tokens associated with this completions choice. */
    logprobs: CompletionsLogProbabilityModel | null;
    /** Reason for finishing */
    finishReason: CompletionsFinishReason | null;
}

/**
 * Representation of the response data from a completions request.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
export declare interface Completions {
    /** A unique identifier associated with this completions response. */
    id: string;
    /**
     * The first timestamp associated with generation activity for this completions response,
     * represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
     */
    created: Date;
    /**
     * Content filtering results for zero or more prompts in the request. In a streaming request,
     * results for different prompts may arrive at different times or in different orders.
     */
    promptFilterResults: ContentFilterResultsForPrompt[];
    /**
     * The collection of completions choices associated with this completions response.
     * Generally, `n` choices are generated per provided prompt with a default value of 1.
     * Token limits and other settings may limit the number of choices generated.
     */
    choices: Choice[];
    /** Usage information for tokens processed and generated as part of this completions operation. */
    usage: CompletionsUsage;
}

/** Representation of the manner in which a completions response concluded. */
/** "stop", "length", "content_filter", "function_call", "tool_calls" */
export declare type CompletionsFinishReason = string;

/** Representation of a log probabilities model for a completions generation. */
export declare interface CompletionsLogProbabilityModel {
    /** The textual forms of tokens evaluated in this probability model. */
    tokens: string[];
    /** A collection of log probability values for the tokens in this completions data. */
    tokenLogprobs: (number | null)[];
    /** A mapping of tokens to maximum log probability values in this completions data. */
    topLogprobs: Record<string, number | null>[];
    /** The text offsets associated with tokens in this completions data. */
    textOffset: number[];
}

/** Representation of a log probabilities model for a completions generation. */
export declare interface CompletionsLogProbabilityModel {
    /** The textual forms of tokens evaluated in this probability model. */
    tokens: string[];
    /** A collection of log probability values for the tokens in this completions data. */
    tokenLogprobs: (number | null)[];
    /** A mapping of tokens to maximum log probability values in this completions data. */
    topLogprobs: Record<string, number | null>[];
    /** The text offsets associated with tokens in this completions data. */
    textOffset: number[];
}

/**
 * Representation of the token counts processed for a completions request.
 * Counts consider all tokens across prompts, choices, choice alternates, bestOf generations, and
 * other consumers.
 */
export declare interface CompletionsUsage {
    /** The number of tokens generated across all completions emissions. */
    completionTokens: number;
    /** The number of tokens in the provided prompts for the completions request. */
    promptTokens: number;
    /** The total number of tokens processed for the completions request and response. */
    totalTokens: number;
}

/** Represents the outcome of an evaluation against a custom blocklist as performed by content filtering. */
export declare interface ContentFilterBlocklistIdResult {
    /** The ID of the custom blocklist evaluated. */
    id: string;
    /** A value indicating whether or not the content has been filtered. */
    filtered: boolean;
}

/** Represents the outcome of a detection operation against protected resources as performed by content filtering. */
export declare interface ContentFilterCitedDetectionResult {
    /** A value indicating whether or not the content has been filtered. */
    filtered: boolean;
    /** A value indicating whether detection occurred, irrespective of severity or whether the content was filtered. */
    detected: boolean;
    /** The internet location associated with the detection. */
    url?: string;
    /** The license description associated with the detection. */
    license: string;
}

/** Represents the outcome of a detection operation performed by content filtering. */
export declare interface ContentFilterDetectionResult {
    /** A value indicating whether or not the content has been filtered. */
    filtered: boolean;
    /** A value indicating whether detection occurred, irrespective of severity or whether the content was filtered. */
    detected: boolean;
}

/** Information about the content filtering error result. */
export declare interface ContentFilterErrorResults {
    /**
     * Describes an error returned if the content filtering system is
     * down or otherwise unable to complete the operation in time.
     */
    error: ErrorModel;
}

/** Information about filtered content severity level and if it has been filtered or not. */
export declare interface ContentFilterResult {
    /** Ratings for the intensity and risk level of filtered content. */
    severity: ContentFilterSeverity;
    /** A value indicating whether or not the content has been filtered. */
    filtered: boolean;
}

/** Information about the content filtering category, if it has been detected. */
export declare type ContentFilterResultDetailsForPrompt = ContentFilterSuccessResultDetailsForPrompt | ContentFilterErrorResults;

/** Information about the content filtering results, if it has been detected. */
export declare type ContentFilterResultsForChoice = ContentFilterSuccessResultsForChoice | ContentFilterErrorResults;

/** Content filtering results for a single prompt in the request. */
export declare interface ContentFilterResultsForPrompt {
    /** The index of this prompt in the set of prompt results */
    promptIndex: number;
    /** Content filtering results for this prompt */
    contentFilterResults: ContentFilterResultDetailsForPrompt;
}

/** Ratings for the intensity and risk level of harmful content. */
/** "safe", "low", "medium", "high" */
export declare type ContentFilterSeverity = string;

/** Information about the content filtering success result. */
export declare interface ContentFilterSuccessResultDetailsForPrompt {
    /**
     * Describes language related to anatomical organs and genitals, romantic relationships,
     *  acts portrayed in erotic or affectionate terms, physical sexual acts, including
     *  those portrayed as an assault or a forced sexual violent act against one’s will,
     *  prostitution, pornography, and abuse.
     */
    sexual?: ContentFilterResult;
    /**
     * Describes language related to physical actions intended to hurt, injure, damage, or
     * kill someone or something; describes weapons, etc.
     */
    violence?: ContentFilterResult;
    /**
     * Describes language attacks or uses that include pejorative or discriminatory language
     * with reference to a person or identity group on the basis of certain differentiating
     * attributes of these groups including but not limited to race, ethnicity, nationality,
     * gender identity and expression, sexual orientation, religion, immigration status, ability
     * status, personal appearance, and body size.
     */
    hate?: ContentFilterResult;
    /**
     * Describes language related to physical actions intended to purposely hurt, injure,
     * or damage one’s body, or kill oneself.
     */
    selfHarm?: ContentFilterResult;
    /**
     * Describes an error returned if the content filtering system is
     * down or otherwise unable to complete the operation in time.
     */
    error?: undefined;
    /** Describes whether profanity was detected. */
    profanity?: ContentFilterDetectionResult;
    /** Describes detection results against configured custom blocklists. */
    customBlocklists?: ContentFilterBlocklistIdResult[];
    /** Whether a jailbreak attempt was detected in the prompt. */
    jailbreak?: ContentFilterDetectionResult;
}

/** Information about content filtering evaluated against generated model output. */
export declare interface ContentFilterSuccessResultsForChoice {
    /**
     * Describes language related to anatomical organs and genitals, romantic relationships,
     *  acts portrayed in erotic or affectionate terms, physical sexual acts, including
     *  those portrayed as an assault or a forced sexual violent act against one’s will,
     *  prostitution, pornography, and abuse.
     */
    sexual?: ContentFilterResult;
    /**
     * Describes language related to physical actions intended to hurt, injure, damage, or
     * kill someone or something; describes weapons, etc.
     */
    violence?: ContentFilterResult;
    /**
     * Describes language attacks or uses that include pejorative or discriminatory language
     * with reference to a person or identity group on the basis of certain differentiating
     * attributes of these groups including but not limited to race, ethnicity, nationality,
     * gender identity and expression, sexual orientation, religion, immigration status, ability
     * status, personal appearance, and body size.
     */
    hate?: ContentFilterResult;
    /**
     * Describes language related to physical actions intended to purposely hurt, injure,
     * or damage one’s body, or kill oneself.
     */
    selfHarm?: ContentFilterResult;
    /** Describes whether profanity was detected. */
    profanity?: ContentFilterDetectionResult;
    /** Describes detection results against configured custom blocklists. */
    customBlocklists?: ContentFilterBlocklistIdResult[];
    /**
     * Describes an error returned if the content filtering system is
     * down or otherwise unable to complete the operation in time.
     */
    error?: undefined;
    /** Information about detection of protected text material. */
    protectedMaterialText?: ContentFilterDetectionResult;
    /** Information about detection of protected code material. */
    protectedMaterialCode?: ContentFilterCitedDetectionResult;
}

/**
 * A specific representation of configurable options for Elasticsearch when using it as an Azure OpenAI chat
 * extension.
 */
export declare interface ElasticsearchChatExtensionConfiguration {
    /**
     * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its
     * default value for Elasticsearch®.
     */
    type: "Elasticsearch";
    /**
     * The authentication method to use when accessing the defined data source.
     * Each data source type supports a specific set of available authentication methods; please see the documentation of
     * the data source for supported mechanisms.
     * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
     * authentication.
     */
    authentication?: OnYourDataAuthenticationOptions;
    /** The configured top number of documents to feature for the configured query. */
    topNDocuments?: number;
    /** Whether queries should be restricted to use of indexed data. */
    inScope?: boolean;
    /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */
    strictness?: number;
    /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */
    roleInformation?: string;
    /** The endpoint of Elasticsearch®. */
    endpoint: string;
    /** The index name of Elasticsearch®. */
    indexName: string;
    /** The index field mapping options of Elasticsearch®. */
    fieldsMapping?: ElasticsearchIndexFieldMappingOptions;
    /** The query type of Elasticsearch®. */
    queryType?: ElasticsearchQueryType;
    /** The embedding dependency for vector search. */
    embeddingDependency?: OnYourDataVectorizationSource;
}

/** Optional settings to control how fields are processed when using a configured Elasticsearch® resource. */
export declare interface ElasticsearchIndexFieldMappingOptions {
    /** The name of the index field to use as a title. */
    titleField?: string;
    /** The name of the index field to use as a URL. */
    urlField?: string;
    /** The name of the index field to use as a filepath. */
    filepathField?: string;
    /** The names of index fields that should be treated as content. */
    contentFields?: string[];
    /** The separator pattern that content fields should use. */
    contentFieldsSeparator?: string;
    /** The names of fields that represent vector data. */
    vectorFields?: string[];
}

/** The type of Elasticsearch® retrieval query that should be executed when using it as an Azure OpenAI chat extension. */
/** "simple", "vector" */
export declare type ElasticsearchQueryType = "simple" | "vector";

/** Representation of a single embeddings relatedness comparison. */
export declare interface EmbeddingItem {
    /**
     * List of embeddings value for the input prompt. These represent a measurement of the
     * vector-based relatedness of the provided input.
     */
    embedding: number[];
    /** Index of the prompt to which the EmbeddingItem corresponds. */
    index: number;
}

/**
 * Representation of the response data from an embeddings request.
 * Embeddings measure the relatedness of text strings and are commonly used for search, clustering,
 * recommendations, and other similar scenarios.
 */
export declare interface Embeddings {
    /** Embedding values for the prompts submitted in the request. */
    data: EmbeddingItem[];
    /** Usage counts for tokens input using the embeddings API. */
    usage: EmbeddingsUsage;
}

/** Measurement of the amount of tokens used in this request and response. */
export declare interface EmbeddingsUsage {
    /** Number of tokens sent in the original request. */
    promptTokens: number;
    /** Total number of tokens transacted in this request/response. */
    totalTokens: number;
}

/** A readable stream that is iterable and disposable. */
export declare interface EventStream<T> extends ReadableStream<T>, AsyncIterable<T> {
}

/** The name and arguments of a function that should be called, as generated by the model. */
export declare interface FunctionCall {
    /** The name of the function to call. */
    name: string;
    /**
     * The arguments to call the function with, as generated by the model in JSON format.
     * Note that the model does not always generate valid JSON, and may hallucinate parameters
     * not defined by your function schema. Validate the arguments in your code before calling
     * your function.
     */
    arguments: string;
}

/**
 * The collection of predefined behaviors for handling request-provided function information in a chat completions
 * operation.
 */
/** "auto", "none" */
export declare type FunctionCallPreset = "auto" | "none";

/** The definition of a caller-specified function that chat completions may invoke in response to matching user input. */
export declare interface FunctionDefinition {
    /** The name of the function to be called. */
    name: string;
    /**
     * A description of what the function does. The model will use this description when selecting the function and
     * interpreting its parameters.
     */
    description?: string;
    /** The parameters the functions accepts, described as a JSON Schema object. */
    parameters?: Record<string, any>;
}

/**
 * A structure that specifies the exact name of a specific, request-provided function to use when processing a chat
 * completions operation.
 */
export declare interface FunctionName {
    /** The name of the function to call. */
    name: string;
}

/** The options for an audio transcription request */
export declare interface GetAudioTranscriptionOptions extends OperationOptions {
    /** An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language. */
    prompt?: string;
    /**
     * The sampling temperature, between 0 and 1.
     * Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
     * If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
     */
    temperature?: number;
    /** The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. */
    language?: string;
}

/** The options for an audio translation request */
export declare interface GetAudioTranslationOptions extends OperationOptions {
    /** An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language. */
    prompt?: string;
    /**
     * The sampling temperature, between 0 and 1.
     * Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
     * If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
     */
    temperature?: number;
}

/**
 * This module contains models that we want to live side-by-side with the
 * corresponding generated models. This is useful for providing customer-facing
 * models that have different names/types than the generated models.
 */
export declare interface GetChatCompletionsOptions extends OperationOptions {
    /** A list of functions the model may generate JSON inputs for. */
    functions?: FunctionDefinition[];
    /**
     * Controls how the model responds to function calls. "none" means the model does not call a function,
     * and responds to the end-user. "auto" means the model can pick between an end-user or calling a function.
     *  Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.
     *  "none" is the default when no functions are present. "auto" is the default if functions are present.
     */
    functionCall?: FunctionCallPreset | FunctionName;
    /** The maximum number of tokens to generate. */
    maxTokens?: number;
    /**
     * The sampling temperature to use that controls the apparent creativity of generated completions.
     * Higher values will make output more random while lower values will make results more focused
     * and deterministic.
     * It is not recommended to modify temperature and topP for the same completions request as the
     * interaction of these two settings is difficult to predict.
     */
    temperature?: number;
    /**
     * An alternative to sampling with temperature called nucleus sampling. This value causes the
     * model to consider the results of tokens with the provided probability mass. As an example, a
     * value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be
     * considered.
     * It is not recommended to modify temperature and topP for the same completions request as the
     * interaction of these two settings is difficult to predict.
     */
    topP?: number;
    /**
     * A map between GPT token IDs and bias scores that influences the probability of specific tokens
     * appearing in a completions response. Token IDs are computed via external tokenizer tools, while
     * bias scores reside in the range of -100 to 100 with minimum and maximum values corresponding to
     * a full ban or exclusive selection of a token, respectively. The exact behavior of a given bias
     * score varies by model.
     */
    logitBias?: Record<string, number>;
    /**
     * An identifier for the caller or end user of the operation. This may be used for tracking
     * or rate-limiting purposes.
     */
    user?: string;
    /**
     * The number of chat completions choices that should be generated for a chat completions
     * response.
     * Because this setting can generate many completions, it may quickly consume your token quota.
     * Use carefully and ensure reasonable settings for maxTokens and stop.
     */
    n?: number;
    /** A collection of textual sequences that will end completions generation. */
    stop?: string[];
    /**
     * A value that influences the probability of generated tokens appearing based on their existing
     * presence in generated text.
     * Positive values will make tokens less likely to appear when they already exist and increase the
     * model's likelihood to output new topics.
     */
    presencePenalty?: number;
    /**
     * A value that influences the probability of generated tokens appearing based on their cumulative
     * frequency in generated text.
     * Positive values will make tokens less likely to appear as their frequency increases and
     * decrease the likelihood of the model repeating the same statements verbatim.
     */
    frequencyPenalty?: number;
    /**
     * If specified, the system will make a best effort to sample deterministically such that repeated requests with the
     * same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the
     * system_fingerprint response parameter to monitor changes in the backend."
     */
    seed?: number;
    /** An object specifying the format that the model must output. Used to enable JSON mode. */
    responseFormat?: ChatCompletionsResponseFormat;
    /** The available tool definitions that the chat completions request can use, including caller-defined functions. */
    tools?: ChatCompletionsToolDefinition[];
    /** If specified, the model will configure which of the provided tools it can use for the chat completions response. */
    toolChoice?: ChatCompletionsNamedToolSelection;
    /**
     *   The configuration entries for Azure OpenAI chat extensions that use them.
     *   This additional specification is only compatible with Azure OpenAI.
     */
    azureExtensionOptions?: AzureExtensionsOptions;
}

/**
 * The configuration information for a completions request.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
export declare interface GetCompletionsOptions extends OperationOptions {
    /** The maximum number of tokens to generate. */
    maxTokens?: number;
    /**
     * The sampling temperature to use that controls the apparent creativity of generated completions.
     * Higher values will make output more random while lower values will make results more focused
     * and deterministic.
     * It is not recommended to modify temperature and top_p for the same completions request as the
     * interaction of these two settings is difficult to predict.
     */
    temperature?: number;
    /**
     * An alternative to sampling with temperature called nucleus sampling. This value causes the
     * model to consider the results of tokens with the provided probability mass. As an example, a
     * value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be
     * considered.
     * It is not recommended to modify temperature and top_p for the same completions request as the
     * interaction of these two settings is difficult to predict.
     */
    topP?: number;
    /**
     * A map between GPT token IDs and bias scores that influences the probability of specific tokens
     * appearing in a completions response. Token IDs are computed via external tokenizer tools, while
     * bias scores reside in the range of -100 to 100 with minimum and maximum values corresponding to
     * a full ban or exclusive selection of a token, respectively. The exact behavior of a given bias
     * score varies by model.
     */
    logitBias?: Record<string, number>;
    /**
     * An identifier for the caller or end user of the operation. This may be used for tracking
     * or rate-limiting purposes.
     */
    user?: string;
    /**
     * The number of completions choices that should be generated per provided prompt as part of an
     * overall completions response.
     * Because this setting can generate many completions, it may quickly consume your token quota.
     * Use carefully and ensure reasonable settings for max_tokens and stop.
     */
    n?: number;
    /**
     * A value that controls the emission of log probabilities for the provided number of most likely
     * tokens within a completions response.
     */
    logprobs?: number;
    /**
     * A value specifying whether completions responses should include input prompts as prefixes to
     * their generated output.
     */
    echo?: boolean;
    /** A collection of textual sequences that will end completions generation. */
    stop?: string[];
    /**
     * A value that influences the probability of generated tokens appearing based on their existing
     * presence in generated text.
     * Positive values will make tokens less likely to appear when they already exist and increase the
     * model's likelihood to output new topics.
     */
    presencePenalty?: number;
    /**
     * A value that influences the probability of generated tokens appearing based on their cumulative
     * frequency in generated text.
     * Positive values will make tokens less likely to appear as their frequency increases and
     * decrease the likelihood of the model repeating the same statements verbatim.
     */
    frequencyPenalty?: number;
    /**
     * A value that controls how many completions will be internally generated prior to response
     * formulation.
     * When used together with n, best_of controls the number of candidate completions and must be
     * greater than n.
     * Because this setting can generate many completions, it may quickly consume your token quota.
     * Use carefully and ensure reasonable settings for max_tokens and stop.
     */
    bestOf?: number;
}

/** Options for to custom embeddings request */
export declare interface GetEmbeddingsOptions extends OperationOptions {
    /**
     * An identifier for the caller or end user of the operation. This may be used for tracking
     * or rate-limiting purposes.
     */
    user?: string;
    /**
     * The model name to provide as part of this embeddings request.
     * Not applicable to Azure OpenAI, where deployment information should be included in the Azure
     * resource URI that's connected to.
     */
    model?: string;
}

/** Represents the request data used to generate images. */
export declare interface GetImagesOptions extends OperationOptions {
    /**
     * The number of images to generate.
     * Dall-e-3 models only support a value of 1.
     */
    n?: number;
    /**
     * The desired dimensions for generated images.
     * Dall-e-3 models support 1024x1024, 1792x1024, or 1024x1792.
     */
    size?: ImageSize;
    /** The format in which image generation response items should be presented. */
    responseFormat?: ImageGenerationResponseFormat;
    /**
     * The desired image generation quality level to use.
     */
    quality?: ImageGenerationQuality;
    /**
     * The desired image generation style to use.
     */
    style?: ImageGenerationStyle;
    /** A unique identifier representing your end-user, which can help to monitor and detect abuse. */
    user?: string;
}

/**
 * A representation of a single generated image, provided as either base64-encoded data or as a URL from which the image
 * may be retrieved.
 */
export declare interface ImageGenerationData {
    /** The URL that provides temporary access to download the generated image. */
    url?: string;
    /** The complete data for an image, represented as a base64-encoded string. */
    base64Data?: string;
    /**
     * The final prompt used by the model to generate the image.
     * Only provided with dall-3-models and only when revisions were made to the prompt.
     */
    revisedPrompt?: string;
}

/**
 * An image generation configuration that specifies how the model should prioritize quality, cost, and speed.
 * Only configurable with dall-e-3 models.
 */
/** "standard", "hd" */
export declare type ImageGenerationQuality = "standard" | "hd";

/** The format in which the generated images are returned. */
/** "url", "b64_json" */
export declare type ImageGenerationResponseFormat = "url" | "b64_json";

/** The result of a successful image generation operation. */
export declare interface ImageGenerations {
    /**
     * A timestamp representing when this operation was started.
     * Expressed in seconds since the Unix epoch of 1970-01-01T00:00:00+0000.
     */
    created: Date;
    /** The images generated by the operation. */
    data: ImageGenerationData[];
}

/**
 * An image generation configuration that specifies how the model should incorporate realism and other visual characteristics.
 * Only configurable with dall-e-3 models.
 */
/** "natural", "vivid" */
export declare type ImageGenerationStyle = "natural" | "vivid";

/** The desired size of generated images. */
/** "1024x1024", "1792x1024", "1024x1792" */
export declare type ImageSize = "1024x1024" | "1792x1024" | "1024x1792";

/**
 * A structured representation of a stop reason that signifies a token limit was reached before the model could naturally
 * complete.
 */
export declare interface MaxTokensFinishDetails {
    /** The object type, which is always 'max_tokens' for this object. */
    type: "max_tokens";
}

/** The authentication options for Azure OpenAI On Your Data when using an API key. */
export declare interface OnYourDataApiKeyAuthenticationOptions {
    /** The authentication type of API key. */
    type: "APIKey";
    /** The API key to use for authentication. */
    key: string;
}

/** The authentication options for Azure OpenAI On Your Data. */
export declare type OnYourDataAuthenticationOptions = OnYourDataApiKeyAuthenticationOptions | OnYourDataConnectionStringAuthenticationOptions | OnYourDataKeyAndKeyIdAuthenticationOptions | OnYourDataSystemAssignedManagedIdentityAuthenticationOptions | OnYourDataUserAssignedManagedIdentityAuthenticationOptions;

/** The authentication types supported with Azure OpenAI On Your Data. */
/** "APIKey", "ConnectionString", "KeyAndKeyId", "SystemAssignedManagedIdentity", "UserAssignedManagedIdentity" */
export declare type OnYourDataAuthenticationType = "APIKey" | "ConnectionString" | "KeyAndKeyId" | "SystemAssignedManagedIdentity" | "UserAssignedManagedIdentity";

/** The authentication options for Azure OpenAI On Your Data when using a connection string. */
export declare interface OnYourDataConnectionStringAuthenticationOptions {
    /** The authentication type of connection string. */
    type: "ConnectionString";
    /** The connection string to use for authentication. */
    connectionString: string;
}

/**
 * The details of a a vectorization source, used by Azure OpenAI On Your Data when applying vector search, that is based
 * on an internal embeddings model deployment name in the same Azure OpenAI resource.
 */
export declare interface OnYourDataDeploymentNameVectorizationSource {
    /** The type of vectorization source to use. Always 'DeploymentName' for this type. */
    type: "DeploymentName";
    /** The embedding model deployment name within the same Azure OpenAI resource. This enables you to use vector search without Azure OpenAI api-key and without Azure OpenAI public network access. */
    deploymentName: string;
}

/**
 * The details of a a vectorization source, used by Azure OpenAI On Your Data when applying vector search, that is based
 * on a public Azure OpenAI endpoint call for embeddings.
 */
export declare interface OnYourDataEndpointVectorizationSource {
    /** The type of vectorization source to use. Always 'Endpoint' for this type. */
    type: "Endpoint";
    /** Specifies the resource endpoint URL from which embeddings should be retrieved. It should be in the format of https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/embeddings. The api-version query parameter is not allowed. */
    endpoint: string;
    /** Specifies the authentication options to use when retrieving embeddings from the specified endpoint. */
    authentication: OnYourDataAuthenticationOptions;
}

/** The authentication options for Azure OpenAI On Your Data when using an Elasticsearch key and key ID pair. */
export declare interface OnYourDataKeyAndKeyIdAuthenticationOptions {
    /** The authentication type of Elasticsearch key and key ID pair. */
    type: "KeyAndKeyId";
    /** The key to use for authentication. */
    key: string;
    /** The key ID to use for authentication. */
    keyId: string;
}

/**
 * The details of a a vectorization source, used by Azure OpenAI On Your Data when applying vector search, that is based
 * on a search service model ID. Currently only supported by Elasticsearch®.
 */
export declare interface OnYourDataModelIdVectorizationSource {
    /** The type of vectorization source to use. Always 'ModelId' for this type. */
    type: "ModelId";
    /** The embedding model ID build inside the search service. Currently only supported by Elasticsearch®. */
    modelId: string;
}

/** The authentication options for Azure OpenAI On Your Data when using a system-assigned managed identity. */
export declare interface OnYourDataSystemAssignedManagedIdentityAuthenticationOptions {
    /** The authentication type of system-assigned managed identity. */
    type: "SystemAssignedManagedIdentity";
}

/** The authentication options for Azure OpenAI On Your Data when using a user-assigned managed identity. */
export declare interface OnYourDataUserAssignedManagedIdentityAuthenticationOptions {
    /** The authentication type of user-assigned managed identity. */
    type: "UserAssignedManagedIdentity";
    /** The resource ID of the user-assigned managed identity to use for authentication. */
    managedIdentityResourceId: string;
}

/** A representation of a vectorization source for Azure OpenAI On Your Data with vector search. */
export declare type OnYourDataVectorizationSource = OnYourDataEndpointVectorizationSource | OnYourDataDeploymentNameVectorizationSource | OnYourDataModelIdVectorizationSource;

/**
 * Represents the available sources Azure OpenAI On Your Data can use to configure vectorization of data for use with
 * vector search.
 */
/** "Endpoint", "DeploymentName", "ModelId" */
export declare type OnYourDataVectorizationSourceType = "Endpoint" | "DeploymentName" | "ModelId";

/**
 * A client for interacting with Azure OpenAI.
 *
 * The client needs the endpoint of an OpenAI resource and an authentication
 * method such as an API key or token. The API key and endpoint can be found in
 * the OpenAI resource page. They will be located in the resource's Keys and Endpoint page.
 *
 * ### Examples for authentication:
 *
 * #### API Key
 *
 * ```js
 * import { OpenAIClient } from "@azure/openai";
 * import { AzureKeyCredential } from "@azure/core-auth";
 *
 * const endpoint = "<azure endpoint>";
 * const credential = new AzureKeyCredential("<api key>");
 *
 * const client = new OpenAIClient(endpoint, credential);
 * ```
 *
 * #### Azure Active Directory
 *
 * ```js
 * import { OpenAIClient } from "@azure/openai";
 * import { DefaultAzureCredential } from "@azure/identity";
 *
 * const endpoint = "<azure endpoint>";
 * const credential = new DefaultAzureCredential();
 *
 * const client = new OpenAIClient(endpoint, credential);
 * ```
 */
export declare class OpenAIClient {
    private _client;
    private _isAzure;
    /**
     * Initializes an instance of OpenAIClient for use with an Azure OpenAI resource.
     * @param endpoint - The URI for an Azure OpenAI resource, including protocol and hostname.
     *                 For example: https://my-resource.openai.azure.com.
     * @param credential - A key credential used to authenticate to an Azure OpenAI resource.
     * @param options - The options for configuring the client.
     * @remarks
     *   This constructor initializes an OpenAIClient object that can only be used with Azure OpenAI resources.
     *   To use OpenAIClient with a non-Azure OpenAI inference endpoint, use a constructor that accepts a non-Azure OpenAI API key instead.
     */
    constructor(endpoint: string, credential: KeyCredential, options?: OpenAIClientOptions);
    /**
     * Initializes an instance of OpenAIClient for use with an Azure OpenAI resource.
     * @param endpoint - The URI for an Azure OpenAI resource, including protocol and hostname.
     *                 For example: https://my-resource.openai.azure.com.
     * @param credential - A token credential used to authenticate with an Azure OpenAI resource.
     * @param options - The options for configuring the client.
     */
    constructor(endpoint: string, credential: TokenCredential, options?: OpenAIClientOptions);
    /**
     * Initializes an instance of OpenAIClient for use with the non-Azure OpenAI endpoint.
     * @param openAiApiKey - The API key to use when connecting to the non-Azure OpenAI endpoint.
     * @param options - The options for configuring the client.
     * @remarks
     *   OpenAIClient objects initialized with this constructor can only be used with the non-Azure OpenAI inference endpoint.
     *   To use OpenAIClient with an Azure OpenAI resource, use a constructor that accepts a resource URI and Azure authentication credential instead.
     */
    constructor(openAiApiKey: KeyCredential, options?: OpenAIClientOptions);
    /**
     * Returns textual completions as configured for a given prompt.
     * @param deploymentName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this completions request.
     * @returns The completions for the given prompt.
     */
    getCompletions(deploymentName: string, prompt: string[], options?: GetCompletionsOptions): Promise<Completions>;
    /**
     * Lists the completions tokens as they become available for a given prompt.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The completions options for this completions request.
     * @returns An asynchronous iterable of completions tokens.
     */
    streamCompletions(deploymentName: string, prompt: string[], options?: GetCompletionsOptions): Promise<EventStream<Omit<Completions, "usage">>>;
    /**
     * Return the computed embeddings for a given prompt.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param input - The prompt to use for this request.
     * @param options - The embeddings options for this embeddings request.
     * @returns The embeddings for the given prompt.
     */
    getEmbeddings(deploymentName: string, input: string[], options?: GetEmbeddingsOptions): Promise<Embeddings>;
    /**
     * Get chat completions for provided chat context messages.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this completions request.
     * @returns The chat completions for the given chat context messages.
     */
    getChatCompletions(deploymentName: string, messages: ChatRequestMessage[], options?: GetChatCompletionsOptions): Promise<ChatCompletions>;
    /**
     * Lists the chat completions tokens as they become available for a chat context.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this chat completions request.
     * @returns An asynchronous iterable of chat completions tokens.
     */
    streamChatCompletions(deploymentName: string, messages: ChatRequestMessage[], options?: GetChatCompletionsOptions): Promise<EventStream<ChatCompletions>>;
    /**
     * Starts the generation of a batch of images from a text caption
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this image request.
     * @returns The image generation response (containing url or base64 data).
     */
    getImages(deploymentName: string, prompt: string, options?: GetImagesOptions): Promise<ImageGenerations>;
    /**
     * Returns the transcription of an audio file in a simple JSON format.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param fileContent - The content of the audio file to transcribe.
     * @param options - The options for this audio transcription request.
     * @returns The audio transcription result in a simple JSON format.
     */
    getAudioTranscription(deploymentName: string, fileContent: Uint8Array, options?: GetAudioTranscriptionOptions): Promise<AudioResultSimpleJson>;
    /**
     * Returns the transcription of an audio file.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param fileContent - The content of the audio file to transcribe.
     * @param format - The format of the result object. See {@link AudioResultFormat} for possible values.
     * @param options - The options for this audio transcription request.
     * @returns The audio transcription result in a format of your choice.
     */
    getAudioTranscription<Format extends AudioResultFormat>(deploymentName: string, fileContent: Uint8Array, format: Format, options?: GetAudioTranscriptionOptions): Promise<AudioResult<Format>>;
    /**
     * Returns the translation of an audio file.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param fileContent - The content of the audio file to translate.
     * @param options - The options for this audio translation request.
     * @returns The audio translation result.
     */
    getAudioTranslation(deploymentName: string, fileContent: Uint8Array, options?: GetAudioTranslationOptions): Promise<AudioResultSimpleJson>;
    /**
     * Returns the translation of an audio file.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param fileContent - The content of the audio file to translate.
     * @param format - The format of the result object. See {@link AudioResultFormat} for possible values.
     * @param options - The options for this audio translation request.
     * @returns The audio translation result.
     */
    getAudioTranslation<Format extends AudioResultFormat>(deploymentName: string, fileContent: Uint8Array, format: Format, options?: GetAudioTranslationOptions): Promise<AudioResult<Format>>;
    private setModel;
}

export declare interface OpenAIClientOptions extends ClientOptions {
}

/**
 * The OpenAIKeyCredential class represents an OpenAI API key
 * and is used to authenticate into an OpenAI client for
 * an OpenAI endpoint.
 */
export declare class OpenAIKeyCredential implements KeyCredential {
    private _key;
    /**
     * Create an instance of an AzureKeyCredential for use
     * with a service client.
     *
     * @param key - The initial value of the key to use in authentication
     */
    constructor(key: string);
    /**
     * The value of the key to be used in authentication
     */
    get key(): string;
    /**
     * Change the value of the key.
     *
     * Updates will take effect upon the next request after
     * updating the key value.
     *
     * @param newKey - The new key value to be used
     */
    update(newKey: string): void;
}

/**
 * A specific representation of configurable options for Elasticsearch when using it as an Azure OpenAI chat
 * extension.
 */
export declare interface PineconeChatExtensionConfiguration {
    /**
     * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its
     * default value for Pinecone.
     */
    type: "Pinecone";
    /**
     * The authentication method to use when accessing the defined data source.
     * Each data source type supports a specific set of available authentication methods; please see the documentation of
     * the data source for supported mechanisms.
     * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
     * authentication.
     */
    authentication?: OnYourDataAuthenticationOptions;
    /** The configured top number of documents to feature for the configured query. */
    topNDocuments?: number;
    /** Whether queries should be restricted to use of indexed data. */
    inScope?: boolean;
    /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */
    strictness?: number;
    /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */
    roleInformation?: string;
    /** The environment name of Pinecone. */
    environment: string;
    /** The name of the Pinecone database index. */
    indexName: string;
    /** Customized field mapping behavior to use when interacting with the search index. */
    fieldsMapping: PineconeFieldMappingOptions;
    /** The embedding dependency for vector search. */
    embeddingDependency?: OnYourDataVectorizationSource;
}

/** Optional settings to control how fields are processed when using a configured Pinecone resource. */
export declare interface PineconeFieldMappingOptions {
    /** The name of the index field to use as a title. */
    titleField?: string;
    /** The name of the index field to use as a URL. */
    urlField?: string;
    /** The name of the index field to use as a filepath. */
    filepathField?: string;
    /** The names of index fields that should be treated as content. */
    contentFields?: string[];
    /** The separator pattern that content fields should use. */
    contentFieldsSeparator?: string;
    /** The names of fields that represent vector data. */
    vectorFields?: string[];
    /** The names of fields that represent image vector data. */
    imageVectorFields?: string[];
}

/** A structured representation of a stop reason that signifies natural termination by the model. */
export declare interface StopFinishDetails {
    /** The object type, which is always 'stop' for this object. */
    type: "stop";
    /** The token sequence that the model terminated with. */
    stop: string;
}

export { }
