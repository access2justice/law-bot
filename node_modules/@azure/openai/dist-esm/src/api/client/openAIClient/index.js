// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
import { __rest } from "tslib";
/**
 * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!
 *
 * Any changes you make here may be lost.
 *
 * If you need to make changes, please do so in the original source file, \{project-root\}/sources/custom
 */
import { operationOptionsToRequestParameters } from "@azure-rest/core-client";
import { createFile } from "@azure/core-rest-pipeline";
import { uint8ArrayToString } from "@azure/core-util";
import { isUnexpected, } from "../../../rest/index.js";
import { getOaiSSEs } from "../../oaiSse.js";
import { camelCaseKeys, snakeCaseKeys } from "../../util.js";
import { getChatCompletionsResult, getCompletionsResult } from "./deserializers.js";
export function _getAudioTranscriptionAsPlainTextSend(context, deploymentId, body, options = {
    requestOptions: {},
}) {
    return context.path("/deployments/{deploymentId}/audio/transcriptions", deploymentId).post(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { body: {
            file: uint8ArrayToString(body["file"], "base64"),
            filename: body["filename"],
            response_format: body["responseFormat"],
            language: body["language"],
            prompt: body["prompt"],
            temperature: body["temperature"],
            model: body["model"],
        } }));
}
export async function _getAudioTranscriptionAsPlainTextDeserialize(result) {
    if (isUnexpected(result)) {
        throw result.body;
    }
    return result.body;
}
/**
 * Gets transcribed text and associated metadata from provided spoken audio data. Audio will be transcribed in the
 * written language corresponding to the language it was spoken in.
 */
export async function getAudioTranscriptionAsPlainText(context, deploymentId, body, options = {
    requestOptions: {},
}) {
    const result = await _getAudioTranscriptionAsPlainTextSend(context, deploymentId, body, options);
    return _getAudioTranscriptionAsPlainTextDeserialize(result);
}
export function _getAudioTranscriptionAsResponseObjectSend(context, deploymentId, body, options = {
    requestOptions: {},
}) {
    var _a;
    return context.path("/deployments/{deploymentId}/audio/transcriptions", deploymentId).post(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { contentType: (_a = options.contentType) !== null && _a !== void 0 ? _a : "multipart/form-data", body: {
            file: uint8ArrayToString(body["file"], "base64"),
            filename: body["filename"],
            response_format: body["responseFormat"],
            language: body["language"],
            prompt: body["prompt"],
            temperature: body["temperature"],
            model: body["model"],
        } }));
}
export async function _getAudioTranscriptionAsResponseObjectDeserialize(result) {
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        text: result.body["text"],
        task: result.body["task"],
        language: result.body["language"],
        duration: result.body["duration"],
        segments: !result.body["segments"]
            ? result.body["segments"]
            : result.body["segments"].map((p) => ({
                id: p["id"],
                start: p["start"],
                end: p["end"],
                text: p["text"],
                temperature: p["temperature"],
                avgLogprob: p["avg_logprob"],
                compressionRatio: p["compression_ratio"],
                noSpeechProb: p["no_speech_prob"],
                tokens: p["tokens"],
                seek: p["seek"],
            })),
    };
}
/**
 * Gets transcribed text and associated metadata from provided spoken audio data. Audio will be transcribed in the
 * written language corresponding to the language it was spoken in.
 */
export async function getAudioTranscriptionAsResponseObject(context, deploymentId, body, options = {
    requestOptions: {},
}) {
    const result = await _getAudioTranscriptionAsResponseObjectSend(context, deploymentId, body, options);
    return _getAudioTranscriptionAsResponseObjectDeserialize(result);
}
export function _getAudioTranslationAsPlainTextSend(context, deploymentId, body, options = {
    requestOptions: {},
}) {
    return context.path("/deployments/{deploymentId}/audio/translations", deploymentId).post(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { body: {
            file: uint8ArrayToString(body["file"], "base64"),
            filename: body["filename"],
            response_format: body["responseFormat"],
            prompt: body["prompt"],
            temperature: body["temperature"],
            model: body["model"],
        } }));
}
export async function _getAudioTranslationAsPlainTextDeserialize(result) {
    if (isUnexpected(result)) {
        throw result.body;
    }
    return result.body;
}
/** Gets English language transcribed text and associated metadata from provided spoken audio data. */
export async function getAudioTranslationAsPlainText(context, deploymentId, body, options = {
    requestOptions: {},
}) {
    const result = await _getAudioTranslationAsPlainTextSend(context, deploymentId, body, options);
    return _getAudioTranslationAsPlainTextDeserialize(result);
}
export function _getAudioTranslationAsResponseObjectSend(context, deploymentId, body, options = {
    requestOptions: {},
}) {
    var _a;
    return context.path("/deployments/{deploymentId}/audio/translations", deploymentId).post(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { contentType: (_a = options.contentType) !== null && _a !== void 0 ? _a : "multipart/form-data", body: {
            file: uint8ArrayToString(body["file"], "base64"),
            filename: body["filename"],
            response_format: body["responseFormat"],
            prompt: body["prompt"],
            temperature: body["temperature"],
            model: body["model"],
        } }));
}
export async function _getAudioTranslationAsResponseObjectDeserialize(result) {
    if (isUnexpected(result)) {
        throw result.body;
    }
    return {
        text: result.body["text"],
        task: result.body["task"],
        language: result.body["language"],
        duration: result.body["duration"],
        segments: !result.body["segments"]
            ? result.body["segments"]
            : result.body["segments"].map((p) => ({
                id: p["id"],
                start: p["start"],
                end: p["end"],
                text: p["text"],
                temperature: p["temperature"],
                avgLogprob: p["avg_logprob"],
                compressionRatio: p["compression_ratio"],
                noSpeechProb: p["no_speech_prob"],
                tokens: p["tokens"],
                seek: p["seek"],
            })),
    };
}
/** Gets English language transcribed text and associated metadata from provided spoken audio data. */
export async function getAudioTranslationAsResponseObject(context, deploymentId, body, options = {
    requestOptions: {},
}) {
    const result = await _getAudioTranslationAsResponseObjectSend(context, deploymentId, body, options);
    return _getAudioTranslationAsResponseObjectDeserialize(result);
}
export function _getCompletionsSend(context, deploymentId, body, options = { requestOptions: {} }) {
    return context.path("/deployments/{deploymentId}/completions", deploymentId).post(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { body: {
            prompt: body["prompt"],
            max_tokens: body["maxTokens"],
            temperature: body["temperature"],
            top_p: body["topP"],
            logit_bias: body["logitBias"],
            user: body["user"],
            n: body["n"],
            logprobs: body["logprobs"],
            echo: body["echo"],
            stop: body["stop"],
            presence_penalty: body["presencePenalty"],
            frequency_penalty: body["frequencyPenalty"],
            best_of: body["bestOf"],
            stream: body["stream"],
            model: body["model"],
        } }));
}
/**
 * Gets completions for the provided input prompts.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
export async function getCompletions(context, deploymentName, prompt, options = { requestOptions: {} }) {
    const { abortSignal, onResponse, requestOptions, tracingOptions } = options, rest = __rest(options, ["abortSignal", "onResponse", "requestOptions", "tracingOptions"]);
    const response = await _getCompletionsSend(context, deploymentName, Object.assign({ prompt }, rest), { abortSignal, onResponse, requestOptions, tracingOptions });
    return _getCompletionsDeserialize(response);
}
export async function _getCompletionsDeserialize(result) {
    if (isUnexpected(result)) {
        throw result.body.error;
    }
    return getCompletionsResult(result.body);
}
export async function _getChatCompletionsDeserialize(result) {
    if (isUnexpected(result)) {
        throw result.body.error;
    }
    return getChatCompletionsResult(result.body);
}
export function _getImageGenerationsSend(context, deploymentId, body, options = { requestOptions: {} }) {
    return context.path("/deployments/{deploymentId}/images/generations", deploymentId).post(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { body: {
            model: body["model"],
            prompt: body["prompt"],
            n: body["n"],
            size: body["size"],
            response_format: body["responseFormat"],
            quality: body["quality"],
            style: body["style"],
            user: body["user"],
        } }));
}
export async function _getImageGenerationsDeserialize(result) {
    if (isUnexpected(result)) {
        throw result.body.error;
    }
    return {
        created: new Date(result.body["created"]),
        data: result.body["data"].map((p) => ({
            url: p["url"],
            base64Data: p["b64_json"],
            revisedPrompt: p["revised_prompt"],
        })),
    };
}
/** Creates an image given a prompt. */
export async function getImageGenerations(context, deploymentId, body, options = { requestOptions: {} }) {
    const result = await _getImageGenerationsSend(context, deploymentId, body, options);
    return _getImageGenerationsDeserialize(result);
}
export function _getEmbeddingsSend(context, deploymentId, body, options = { requestOptions: {} }) {
    return context.path("/deployments/{deploymentId}/embeddings", deploymentId).post(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { body: { user: body["user"], model: body["model"], input: body["input"] } }));
}
export async function _getEmbeddingsDeserialize(result) {
    if (isUnexpected(result)) {
        throw result.body.error;
    }
    return {
        data: result.body["data"].map((p) => ({
            embedding: p["embedding"],
            index: p["index"],
        })),
        usage: {
            promptTokens: result.body.usage["prompt_tokens"],
            totalTokens: result.body.usage["total_tokens"],
        },
    };
}
/** Return the embeddings for a given prompt. */
export async function getEmbeddings(context, deploymentId, body, options = { requestOptions: {} }) {
    const result = await _getEmbeddingsSend(context, deploymentId, body, options);
    return _getEmbeddingsDeserialize(result);
}
export function streamCompletions(context, deploymentName, prompt, options = { requestOptions: {} }) {
    const { abortSignal, onResponse, requestOptions, tracingOptions } = options, rest = __rest(options, ["abortSignal", "onResponse", "requestOptions", "tracingOptions"]);
    const response = _getCompletionsSend(context, deploymentName, Object.assign(Object.assign({ prompt }, rest), { stream: true }), { abortSignal, onResponse, requestOptions, tracingOptions });
    return getOaiSSEs(response, getCompletionsResult);
}
export async function getImages(context, deploymentName, prompt, options = { requestOptions: {} }) {
    const { abortSignal, onResponse, requestOptions, tracingOptions } = options, rest = __rest(options, ["abortSignal", "onResponse", "requestOptions", "tracingOptions"]);
    const result = await _getImageGenerationsSend(context, deploymentName, Object.assign({ prompt }, rest), { abortSignal, onResponse, requestOptions, tracingOptions });
    return _getImageGenerationsDeserialize(result);
}
export function streamChatCompletions(context, deploymentName, messages, options = { requestOptions: {} }) {
    const response = _getChatCompletionsSendX(context, deploymentName, messages, Object.assign(Object.assign({}, options), { stream: true }));
    return getOaiSSEs(response, getChatCompletionsResult);
}
/**
 * Gets chat completions for the provided chat messages.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
export async function getChatCompletions(context, deploymentName, messages, options = { requestOptions: {} }) {
    const result = await _getChatCompletionsSendX(context, deploymentName, messages, options);
    return _getChatCompletionsDeserialize(result);
}
export async function getAudioTranslation(context, deploymentName, fileContent, formatOrOptions, inputOptions) {
    const options = inputOptions !== null && inputOptions !== void 0 ? inputOptions : (typeof formatOrOptions === "string" ? {} : formatOrOptions !== null && formatOrOptions !== void 0 ? formatOrOptions : {});
    const response_format = typeof formatOrOptions === "string" ? formatOrOptions : undefined;
    const { abortSignal, onResponse, requestOptions, tracingOptions } = options, rest = __rest(options, ["abortSignal", "onResponse", "requestOptions", "tracingOptions"]);
    const { body, status } = await context
        .pathUnchecked("deployments/{deploymentName}/audio/translations", deploymentName)
        .post(Object.assign(Object.assign({}, operationOptionsToRequestParameters({
        abortSignal,
        onResponse,
        tracingOptions,
        requestOptions,
    })), { contentType: "multipart/form-data", body: Object.assign(Object.assign(Object.assign({}, snakeCaseKeys(rest)), { file: createFile(fileContent, "placeholder.wav") }), (response_format ? { response_format } : {})) }));
    if (status !== "200") {
        throw body.error;
    }
    return response_format !== "verbose_json"
        ? body
        : camelCaseKeys(body);
}
export async function getAudioTranscription(context, deploymentName, fileContent, formatOrOptions, inputOptions) {
    const options = inputOptions !== null && inputOptions !== void 0 ? inputOptions : (typeof formatOrOptions === "string" ? {} : formatOrOptions !== null && formatOrOptions !== void 0 ? formatOrOptions : {});
    const response_format = typeof formatOrOptions === "string" ? formatOrOptions : undefined;
    const { abortSignal, onResponse, requestOptions, tracingOptions } = options, rest = __rest(options, ["abortSignal", "onResponse", "requestOptions", "tracingOptions"]);
    const { body, status } = await context
        .pathUnchecked("deployments/{deploymentName}/audio/transcriptions", deploymentName)
        .post(Object.assign(Object.assign({}, operationOptionsToRequestParameters({
        abortSignal,
        onResponse,
        tracingOptions,
        requestOptions,
    })), { contentType: "multipart/form-data", body: Object.assign(Object.assign(Object.assign({}, snakeCaseKeys(rest)), { file: createFile(fileContent, "placeholder.wav") }), (response_format ? { response_format } : {})) }));
    if (status !== "200") {
        throw body.error;
    }
    return response_format !== "verbose_json"
        ? body
        : camelCaseKeys(body);
}
function _getChatCompletionsSendX(context, deploymentName, messages, options = { requestOptions: {} }) {
    const { azureExtensionOptions, abortSignal, onResponse, requestOptions, tracingOptions } = options, rest = __rest(options, ["azureExtensionOptions", "abortSignal", "onResponse", "requestOptions", "tracingOptions"]);
    const coreOptions = {
        abortSignal,
        onResponse,
        requestOptions,
        tracingOptions,
    };
    const azure = Object.assign(Object.assign({}, (!(azureExtensionOptions === null || azureExtensionOptions === void 0 ? void 0 : azureExtensionOptions.extensions)
        ? {}
        : { dataSources: azureExtensionOptions.extensions })), (!(azureExtensionOptions === null || azureExtensionOptions === void 0 ? void 0 : azureExtensionOptions.enhancements)
        ? {}
        : { enhancements: azureExtensionOptions.enhancements }));
    return azure.dataSources || azure.enhancements
        ? _getChatCompletionsWithAzureExtensionsSend(context, deploymentName, Object.assign(Object.assign({ messages }, rest), azure), coreOptions)
        : _getChatCompletionsSend(context, deploymentName, Object.assign({ messages }, rest), coreOptions);
}
function _getChatCompletionsWithAzureExtensionsSend(context, deploymentName, body, options = { requestOptions: {} }) {
    const { functions, functionCall, messages, dataSources } = body, rest = __rest(body, ["functions", "functionCall", "messages", "dataSources"]);
    return context
        .path("/deployments/{deploymentId}/extensions/chat/completions", deploymentName)
        .post(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { body: Object.assign(Object.assign({}, snakeCaseKeys(rest)), { dataSources: dataSources === null || dataSources === void 0 ? void 0 : dataSources.map((_a) => {
                var { type } = _a, opts = __rest(_a, ["type"]);
                return ({ type, parameters: opts });
            }), functions, function_call: functionCall, messages: messages.map(serializeChatRequestMessage) }) }));
}
function serializeChatRequestMessage(message) {
    if (message.content === undefined) {
        message.content = null;
    }
    switch (message.role) {
        case "assistant": {
            const { functionCall, toolCalls } = message, rest = __rest(message, ["functionCall", "toolCalls"]);
            return Object.assign(Object.assign(Object.assign({}, snakeCaseKeys(rest)), (!toolCalls || toolCalls.length === 0 ? {} : { tool_calls: toolCalls })), (functionCall ? { function_call: functionCall } : {}));
        }
        default: {
            return snakeCaseKeys(message);
        }
    }
}
function _getChatCompletionsSend(context, deploymentName, body, options = { requestOptions: {} }) {
    const { functions, functionCall, messages } = body, rest = __rest(body, ["functions", "functionCall", "messages"]);
    return context.path("/deployments/{deploymentId}/chat/completions", deploymentName).post(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { body: Object.assign(Object.assign({}, snakeCaseKeys(rest)), { functions, function_call: functionCall, messages: messages.map(serializeChatRequestMessage) }) }));
}
export async function _getChatCompletionsWithAzureExtensionsDeserialize() {
    return {};
}
export async function getChatCompletionsWithAzureExtensions(_context, _deploymentId, _body, _options = {}) {
    return {};
}
//# sourceMappingURL=index.js.map