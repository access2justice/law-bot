// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
import { __rest } from "tslib";
/**
 * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!
 *
 * Any changes you make here may be lost.
 *
 * If you need to make changes, please do so in the original source file, \{project-root\}/sources/custom
 */
import { isTokenCredential } from "@azure/core-auth";
import { getAudioTranscription, getAudioTranslation, getImages, streamChatCompletions, streamCompletions, } from "./api/index.js";
import { getChatCompletions, getCompletions, getEmbeddings, } from "./api/client/openAIClient/index.js";
import { createOpenAI } from "./api/index.js";
import { nonAzurePolicy } from "./api/policies/nonAzure.js";
/**
 * A client for interacting with Azure OpenAI.
 *
 * The client needs the endpoint of an OpenAI resource and an authentication
 * method such as an API key or token. The API key and endpoint can be found in
 * the OpenAI resource page. They will be located in the resource's Keys and Endpoint page.
 *
 * ### Examples for authentication:
 *
 * #### API Key
 *
 * ```js
 * import { OpenAIClient } from "@azure/openai";
 * import { AzureKeyCredential } from "@azure/core-auth";
 *
 * const endpoint = "<azure endpoint>";
 * const credential = new AzureKeyCredential("<api key>");
 *
 * const client = new OpenAIClient(endpoint, credential);
 * ```
 *
 * #### Azure Active Directory
 *
 * ```js
 * import { OpenAIClient } from "@azure/openai";
 * import { DefaultAzureCredential } from "@azure/identity";
 *
 * const endpoint = "<azure endpoint>";
 * const credential = new DefaultAzureCredential();
 *
 * const client = new OpenAIClient(endpoint, credential);
 * ```
 */
export class OpenAIClient {
    constructor(endpointOrOpenAiKey, credOrOptions = {}, options = {}) {
        var _a, _b;
        this._isAzure = false;
        let opts;
        let endpoint;
        let cred;
        if (isCred(credOrOptions)) {
            endpoint = endpointOrOpenAiKey;
            cred = credOrOptions;
            opts = options;
            this._isAzure = true;
        }
        else {
            endpoint = createOpenAIEndpoint(1);
            cred = endpointOrOpenAiKey;
            const { credentials } = credOrOptions, restOpts = __rest(credOrOptions, ["credentials"]);
            opts = Object.assign({ credentials: {
                    apiKeyHeaderName: (_a = credentials === null || credentials === void 0 ? void 0 : credentials.apiKeyHeaderName) !== null && _a !== void 0 ? _a : "Authorization",
                    scopes: credentials === null || credentials === void 0 ? void 0 : credentials.scopes,
                } }, restOpts);
        }
        this._client = createOpenAI(endpoint, cred, Object.assign(Object.assign({}, opts), (this._isAzure
            ? {}
            : {
                additionalPolicies: [
                    ...((_b = opts.additionalPolicies) !== null && _b !== void 0 ? _b : []),
                    {
                        position: "perCall",
                        policy: nonAzurePolicy(),
                    },
                ],
            })));
    }
    /**
     * Returns textual completions as configured for a given prompt.
     * @param deploymentName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this completions request.
     * @returns The completions for the given prompt.
     */
    getCompletions(deploymentName, prompt, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getCompletions(this._client, deploymentName, prompt, options);
    }
    /**
     * Lists the completions tokens as they become available for a given prompt.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The completions options for this completions request.
     * @returns An asynchronous iterable of completions tokens.
     */
    streamCompletions(deploymentName, prompt, options = {}) {
        this.setModel(deploymentName, options);
        return streamCompletions(this._client, deploymentName, prompt, options);
    }
    /**
     * Return the computed embeddings for a given prompt.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param input - The prompt to use for this request.
     * @param options - The embeddings options for this embeddings request.
     * @returns The embeddings for the given prompt.
     */
    getEmbeddings(deploymentName, input, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getEmbeddings(this._client, deploymentName, Object.assign({ input }, options), options);
    }
    /**
     * Get chat completions for provided chat context messages.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this completions request.
     * @returns The chat completions for the given chat context messages.
     */
    getChatCompletions(deploymentName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getChatCompletions(this._client, deploymentName, messages, options);
    }
    /**
     * Lists the chat completions tokens as they become available for a chat context.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this chat completions request.
     * @returns An asynchronous iterable of chat completions tokens.
     */
    streamChatCompletions(deploymentName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return streamChatCompletions(this._client, deploymentName, messages, options);
    }
    /**
     * Starts the generation of a batch of images from a text caption
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this image request.
     * @returns The image generation response (containing url or base64 data).
     */
    getImages(deploymentName, prompt, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getImages(this._client, deploymentName, prompt, options);
    }
    async getAudioTranscription(deploymentName, fileContent, formatOrOptions, inputOptions) {
        const options = inputOptions !== null && inputOptions !== void 0 ? inputOptions : (typeof formatOrOptions === "string" ? {} : formatOrOptions !== null && formatOrOptions !== void 0 ? formatOrOptions : {});
        const response_format = typeof formatOrOptions === "string" ? formatOrOptions : undefined;
        this.setModel(deploymentName, options);
        if (response_format === undefined) {
            return getAudioTranscription(this._client, deploymentName, fileContent, options);
        }
        return getAudioTranscription(this._client, deploymentName, fileContent, response_format, options);
    }
    async getAudioTranslation(deploymentName, fileContent, formatOrOptions, inputOptions) {
        const options = inputOptions !== null && inputOptions !== void 0 ? inputOptions : (typeof formatOrOptions === "string" ? {} : formatOrOptions !== null && formatOrOptions !== void 0 ? formatOrOptions : {});
        const response_format = typeof formatOrOptions === "string" ? formatOrOptions : undefined;
        this.setModel(deploymentName, options);
        if (response_format === undefined) {
            return getAudioTranslation(this._client, deploymentName, fileContent, options);
        }
        return getAudioTranslation(this._client, deploymentName, fileContent, response_format, options);
    }
    setModel(model, options) {
        if (!this._isAzure) {
            options.model = model;
        }
    }
}
function createOpenAIEndpoint(version) {
    return `https://api.openai.com/v${version}`;
}
function isCred(cred) {
    return isTokenCredential(cred) || cred.key !== undefined;
}
//# sourceMappingURL=OpenAIClient.js.map