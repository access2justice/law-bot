{"version":3,"file":"models.js","sourceRoot":"","sources":["../../../src/rest/models.ts"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\n/**\n * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!\n *\n * Any changes you make here may be lost.\n *\n * If you need to make changes, please do so in the original source file, \\{project-root\\}/sources/custom\n */\n\n/** The configuration information for an audio transcription request. */\nexport interface AudioTranscriptionOptions {\n  /**\n   * The audio data to transcribe. This must be the binary content of a file in one of the supported media formats:\n   *  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.\n   */\n  file: string;\n  /** The optional filename or descriptive identifier to associate with with the audio data. */\n  filename?: string;\n  /**\n   * The requested format of the transcription response data, which will influence the content and detail of the result.\n   *\n   * Possible values: json, verbose_json, text, srt, vtt\n   */\n  response_format?: string;\n  /**\n   * The primary spoken language of the audio data to be transcribed, supplied as a two-letter ISO-639-1 language code\n   * such as 'en' or 'fr'.\n   * Providing this known input language is optional but may improve the accuracy and/or latency of transcription.\n   */\n  language?: string;\n  /**\n   * An optional hint to guide the model's style or continue from a prior audio segment. The written language of the\n   * prompt should match the primary spoken language of the audio data.\n   */\n  prompt?: string;\n  /**\n   * The sampling temperature, between 0 and 1.\n   * Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n   * If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n  /** The model to use for this transcription request. */\n  model?: string;\n}\n\n/** The configuration information for an audio translation request. */\nexport interface AudioTranslationOptions {\n  /**\n   * The audio data to translate. This must be the binary content of a file in one of the supported media formats:\n   *  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.\n   */\n  file: string;\n  /** The optional filename or descriptive identifier to associate with with the audio data. */\n  filename?: string;\n  /**\n   * The requested format of the translation response data, which will influence the content and detail of the result.\n   *\n   * Possible values: json, verbose_json, text, srt, vtt\n   */\n  response_format?: string;\n  /**\n   * An optional hint to guide the model's style or continue from a prior audio segment. The written language of the\n   * prompt should match the primary spoken language of the audio data.\n   */\n  prompt?: string;\n  /**\n   * The sampling temperature, between 0 and 1.\n   * Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n   * If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n  /** The model to use for this translation request. */\n  model?: string;\n}\n\n/**\n * The configuration information for a completions request.\n * Completions support a wide variety of tasks and generate text that continues from or \"completes\"\n * provided prompt data.\n */\nexport interface CompletionsOptions {\n  /** The prompts to generate completions from. */\n  prompt: string[];\n  /** The maximum number of tokens to generate. */\n  max_tokens?: number;\n  /**\n   * The sampling temperature to use that controls the apparent creativity of generated completions.\n   * Higher values will make output more random while lower values will make results more focused\n   * and deterministic.\n   * It is not recommended to modify temperature and top_p for the same completions request as the\n   * interaction of these two settings is difficult to predict.\n   */\n  temperature?: number;\n  /**\n   * An alternative to sampling with temperature called nucleus sampling. This value causes the\n   * model to consider the results of tokens with the provided probability mass. As an example, a\n   * value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be\n   * considered.\n   * It is not recommended to modify temperature and top_p for the same completions request as the\n   * interaction of these two settings is difficult to predict.\n   */\n  top_p?: number;\n  /**\n   * A map between GPT token IDs and bias scores that influences the probability of specific tokens\n   * appearing in a completions response. Token IDs are computed via external tokenizer tools, while\n   * bias scores reside in the range of -100 to 100 with minimum and maximum values corresponding to\n   * a full ban or exclusive selection of a token, respectively. The exact behavior of a given bias\n   * score varies by model.\n   */\n  logit_bias?: Record<string, number>;\n  /**\n   * An identifier for the caller or end user of the operation. This may be used for tracking\n   * or rate-limiting purposes.\n   */\n  user?: string;\n  /**\n   * The number of completions choices that should be generated per provided prompt as part of an\n   * overall completions response.\n   * Because this setting can generate many completions, it may quickly consume your token quota.\n   * Use carefully and ensure reasonable settings for max_tokens and stop.\n   */\n  n?: number;\n  /**\n   * A value that controls the emission of log probabilities for the provided number of most likely\n   * tokens within a completions response.\n   */\n  logprobs?: number;\n  /**\n   * A value specifying whether completions responses should include input prompts as prefixes to\n   * their generated output.\n   */\n  echo?: boolean;\n  /** A collection of textual sequences that will end completions generation. */\n  stop?: string[];\n  /**\n   * A value that influences the probability of generated tokens appearing based on their existing\n   * presence in generated text.\n   * Positive values will make tokens less likely to appear when they already exist and increase the\n   * model's likelihood to output new topics.\n   */\n  presence_penalty?: number;\n  /**\n   * A value that influences the probability of generated tokens appearing based on their cumulative\n   * frequency in generated text.\n   * Positive values will make tokens less likely to appear as their frequency increases and\n   * decrease the likelihood of the model repeating the same statements verbatim.\n   */\n  frequency_penalty?: number;\n  /**\n   * A value that controls how many completions will be internally generated prior to response\n   * formulation.\n   * When used together with n, best_of controls the number of candidate completions and must be\n   * greater than n.\n   * Because this setting can generate many completions, it may quickly consume your token quota.\n   * Use carefully and ensure reasonable settings for max_tokens and stop.\n   */\n  best_of?: number;\n  /** A value indicating whether chat completions should be streamed for this request. */\n  stream?: boolean;\n  /**\n   * The model name to provide as part of this completions request.\n   * Not applicable to Azure OpenAI, where deployment information should be included in the Azure\n   * resource URI that's connected to.\n   */\n  model?: string;\n}\n\n/**\n * The configuration information for a chat completions request.\n * Completions support a wide variety of tasks and generate text that continues from or \"completes\"\n * provided prompt data.\n */\nexport interface ChatCompletionsOptions {\n  /**\n   * The collection of context messages associated with this chat completions request.\n   * Typical usage begins with a chat message for the System role that provides instructions for\n   * the behavior of the assistant, followed by alternating messages between the User and\n   * Assistant roles.\n   */\n  messages: Array<ChatRequestMessage>;\n  /** A list of functions the model may generate JSON inputs for. */\n  functions?: Array<FunctionDefinition>;\n  /**\n   * Controls how the model responds to function calls. \"none\" means the model does not call a function,\n   * and responds to the end-user. \"auto\" means the model can pick between an end-user or calling a function.\n   *  Specifying a particular function via `{\"name\": \"my_function\"}` forces the model to call that function.\n   *  \"none\" is the default when no functions are present. \"auto\" is the default if functions are present.\n   */\n  function_call?: string | FunctionName;\n  /** The maximum number of tokens to generate. */\n  max_tokens?: number;\n  /**\n   * The sampling temperature to use that controls the apparent creativity of generated completions.\n   * Higher values will make output more random while lower values will make results more focused\n   * and deterministic.\n   * It is not recommended to modify temperature and top_p for the same completions request as the\n   * interaction of these two settings is difficult to predict.\n   */\n  temperature?: number;\n  /**\n   * An alternative to sampling with temperature called nucleus sampling. This value causes the\n   * model to consider the results of tokens with the provided probability mass. As an example, a\n   * value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be\n   * considered.\n   * It is not recommended to modify temperature and top_p for the same completions request as the\n   * interaction of these two settings is difficult to predict.\n   */\n  top_p?: number;\n  /**\n   * A map between GPT token IDs and bias scores that influences the probability of specific tokens\n   * appearing in a completions response. Token IDs are computed via external tokenizer tools, while\n   * bias scores reside in the range of -100 to 100 with minimum and maximum values corresponding to\n   * a full ban or exclusive selection of a token, respectively. The exact behavior of a given bias\n   * score varies by model.\n   */\n  logit_bias?: Record<string, number>;\n  /**\n   * An identifier for the caller or end user of the operation. This may be used for tracking\n   * or rate-limiting purposes.\n   */\n  user?: string;\n  /**\n   * The number of chat completions choices that should be generated for a chat completions\n   * response.\n   * Because this setting can generate many completions, it may quickly consume your token quota.\n   * Use carefully and ensure reasonable settings for max_tokens and stop.\n   */\n  n?: number;\n  /** A collection of textual sequences that will end completions generation. */\n  stop?: string[];\n  /**\n   * A value that influences the probability of generated tokens appearing based on their existing\n   * presence in generated text.\n   * Positive values will make tokens less likely to appear when they already exist and increase the\n   * model's likelihood to output new topics.\n   */\n  presence_penalty?: number;\n  /**\n   * A value that influences the probability of generated tokens appearing based on their cumulative\n   * frequency in generated text.\n   * Positive values will make tokens less likely to appear as their frequency increases and\n   * decrease the likelihood of the model repeating the same statements verbatim.\n   */\n  frequency_penalty?: number;\n  /** A value indicating whether chat completions should be streamed for this request. */\n  stream?: boolean;\n  /**\n   * The model name to provide as part of this completions request.\n   * Not applicable to Azure OpenAI, where deployment information should be included in the Azure\n   * resource URI that's connected to.\n   */\n  model?: string;\n  /**\n   *   The configuration entries for Azure OpenAI chat extensions that use them.\n   *   This additional specification is only compatible with Azure OpenAI.\n   */\n  dataSources?: Array<AzureChatExtensionConfiguration>;\n  /** If provided, the configuration options for available Azure OpenAI chat enhancements. */\n  enhancements?: AzureChatEnhancementConfiguration;\n  /**\n   * If specified, the system will make a best effort to sample deterministically such that repeated requests with the\n   * same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the\n   * system_fingerprint response parameter to monitor changes in the backend.\"\n   */\n  seed?: number;\n  /**\n   * An object specifying the format that the model must output. Used to enable JSON mode.\n   *\n   * Possible values: text, json_object\n   */\n  response_format?: ChatCompletionsResponseFormat;\n  /** The available tool definitions that the chat completions request can use, including caller-defined functions. */\n  tools?: Array<ChatCompletionsToolDefinition>;\n  /** If specified, the model will configure which of the provided tools it can use for the chat completions response. */\n  tool_choice?: string | ChatCompletionsNamedToolSelection;\n}\n\n/** An abstract representation of a chat message as provided in a request. */\nexport interface ChatRequestMessageParent {\n  role: string;\n}\n\n/**\n * A request chat message containing system instructions that influence how the model will generate a chat completions\n * response.\n */\nexport interface ChatRequestSystemMessage extends ChatRequestMessageParent {\n  /** The chat role associated with this message, which is always 'system' for system messages. */\n  role: \"system\";\n  /** The contents of the system message. */\n  content: string;\n  /** An optional name for the participant. */\n  name?: string;\n}\n\n/** A request chat message representing user input to the assistant. */\nexport interface ChatRequestUserMessage extends ChatRequestMessageParent {\n  /** The chat role associated with this message, which is always 'user' for user messages. */\n  role: \"user\";\n  /** The contents of the user message, with available input types varying by selected model. */\n  content: string | Array<ChatMessageContentItem>;\n  /** An optional name for the participant. */\n  name?: string;\n}\n\n/** An abstract representation of a structured content item within a chat message. */\nexport interface ChatMessageContentItemParent {\n  type: string;\n}\n\n/** A structured chat content item containing plain text. */\nexport interface ChatMessageTextContentItem extends ChatMessageContentItemParent {\n  /** The discriminated object type: always 'text' for this type. */\n  type: \"text\";\n  /** The content of the message. */\n  text: string;\n}\n\n/** A structured chat content item containing an image reference. */\nexport interface ChatMessageImageContentItem extends ChatMessageContentItemParent {\n  /** The discriminated object type: always 'image_url' for this type. */\n  type: \"image_url\";\n  /** An internet location, which must be accessible to the model,from which the image may be retrieved. */\n  image_url: ChatMessageImageUrl;\n}\n\n/** An internet location from which the model may retrieve an image. */\nexport interface ChatMessageImageUrl {\n  /** The URL of the image. */\n  url: string;\n  /**\n   * The evaluation quality setting to use, which controls relative prioritization of speed, token consumption, and\n   * accuracy.\n   *\n   * Possible values: auto, low, high\n   */\n  detail?: string;\n}\n\n/** A request chat message representing response or action from the assistant. */\nexport interface ChatRequestAssistantMessage extends ChatRequestMessageParent {\n  /** The chat role associated with this message, which is always 'assistant' for assistant messages. */\n  role: \"assistant\";\n  /** The content of the message. */\n  content: string | null;\n  /** An optional name for the participant. */\n  name?: string;\n  /**\n   * The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat\n   * completions request to resolve as configured.\n   */\n  tool_calls?: Array<ChatCompletionsToolCall>;\n  /**\n   * The function call that must be resolved and have its output appended to subsequent input messages for the chat\n   * completions request to resolve as configured.\n   */\n  function_call?: FunctionCall;\n}\n\n/**\n * An abstract representation of a tool call that must be resolved in a subsequent request to perform the requested\n * chat completion.\n */\nexport interface ChatCompletionsToolCallParent {\n  /** The ID of the tool call. */\n  id: string;\n  type: string;\n}\n\n/**\n * A tool call to a function tool, issued by the model in evaluation of a configured function tool, that represents\n * a function invocation needed for a subsequent chat completions request to resolve.\n */\nexport interface ChatCompletionsFunctionToolCall extends ChatCompletionsToolCallParent {\n  /** The type of tool call, in this case always 'function'. */\n  type: \"function\";\n  /** The details of the function invocation requested by the tool call. */\n  function: FunctionCall;\n}\n\n/** The name and arguments of a function that should be called, as generated by the model. */\nexport interface FunctionCall {\n  /** The name of the function to call. */\n  name: string;\n  /**\n   * The arguments to call the function with, as generated by the model in JSON format.\n   * Note that the model does not always generate valid JSON, and may hallucinate parameters\n   * not defined by your function schema. Validate the arguments in your code before calling\n   * your function.\n   */\n  arguments: string;\n}\n\n/** A request chat message representing requested output from a configured tool. */\nexport interface ChatRequestToolMessage extends ChatRequestMessageParent {\n  /** The chat role associated with this message, which is always 'tool' for tool messages. */\n  role: \"tool\";\n  /** The content of the message. */\n  content: string | null;\n  /** The ID of the tool call resolved by the provided content. */\n  tool_call_id: string;\n}\n\n/** A request chat message representing requested output from a configured function. */\nexport interface ChatRequestFunctionMessage extends ChatRequestMessageParent {\n  /** The chat role associated with this message, which is always 'function' for function messages. */\n  role: \"function\";\n  /** The name of the function that was called to produce output. */\n  name: string;\n  /** The output of the function as requested by the function call. */\n  content: string | null;\n}\n\n/** The definition of a caller-specified function that chat completions may invoke in response to matching user input. */\nexport interface FunctionDefinition {\n  /** The name of the function to be called. */\n  name: string;\n  /**\n   * A description of what the function does. The model will use this description when selecting the function and\n   * interpreting its parameters.\n   */\n  description?: string;\n  /** The parameters the function accepts, described as a JSON Schema object. */\n  parameters?: unknown;\n}\n\n/**\n * A structure that specifies the exact name of a specific, request-provided function to use when processing a chat\n * completions operation.\n */\nexport interface FunctionName {\n  /** The name of the function to call. */\n  name: string;\n}\n\n/**\n *   A representation of configuration data for a single Azure OpenAI chat extension. This will be used by a chat\n *   completions request that should use Azure OpenAI chat extensions to augment the response behavior.\n *   The use of this configuration is compatible only with Azure OpenAI.\n */\nexport interface AzureChatExtensionConfigurationParent {\n  type: string;\n}\n\n/**\n * A specific representation of configurable options for Azure Cognitive Search when using it as an Azure OpenAI chat\n * extension.\n */\nexport interface AzureCognitiveSearchChatExtensionConfiguration\n  extends AzureChatExtensionConfigurationParent {\n  /**\n   * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its\n   * default value for Azure Cognitive Search.\n   */\n  type: \"AzureCognitiveSearch\";\n  /** The parameters to use when configuring Azure Cognitive Search. */\n  parameters: AzureCognitiveSearchChatExtensionParameters;\n}\n\n/** Parameters for Azure Cognitive Search when used as an Azure OpenAI chat extension. */\nexport interface AzureCognitiveSearchChatExtensionParameters {\n  /**\n   * The authentication method to use when accessing the defined data source.\n   * Each data source type supports a specific set of available authentication methods; please see the documentation of\n   * the data source for supported mechanisms.\n   * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)\n   * authentication.\n   */\n  authentication?: OnYourDataAuthenticationOptions;\n  /** The configured top number of documents to feature for the configured query. */\n  topNDocuments?: number;\n  /** Whether queries should be restricted to use of indexed data. */\n  inScope?: boolean;\n  /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */\n  strictness?: number;\n  /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */\n  roleInformation?: string;\n  /** The absolute endpoint path for the Azure Cognitive Search resource to use. */\n  endpoint: string;\n  /** The name of the index to use as available in the referenced Azure Cognitive Search resource. */\n  indexName: string;\n  /** The API key to use when interacting with the Azure Cognitive Search resource. */\n  key?: string;\n  /** Customized field mapping behavior to use when interacting with the search index. */\n  fieldsMapping?: AzureCognitiveSearchIndexFieldMappingOptions;\n  /**\n   * The query type to use with Azure Cognitive Search.\n   *\n   * Possible values: simple, semantic, vector, vectorSimpleHybrid, vectorSemanticHybrid\n   */\n  queryType?: string;\n  /** The additional semantic configuration for the query. */\n  semanticConfiguration?: string;\n  /** Search filter. */\n  filter?: string;\n  /** When using embeddings for search, specifies the resource endpoint URL from which embeddings should be retrieved. It should be in the format of format `https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/embeddings?api-version={api-version}`. */\n  embeddingEndpoint?: string;\n  /** When using embeddings, specifies the API key to use with the provided embeddings endpoint. */\n  embeddingKey?: string;\n  /** The embedding dependency for vector search. */\n  embeddingDependency?: OnYourDataVectorizationSource;\n}\n\n/** The authentication options for Azure OpenAI On Your Data. */\nexport interface OnYourDataAuthenticationOptionsParent {\n  type: string;\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using an API key. */\nexport interface OnYourDataApiKeyAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of API key. */\n  type: \"APIKey\";\n  /** The API key to use for authentication. */\n  key: string;\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using a connection string. */\nexport interface OnYourDataConnectionStringAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of connection string. */\n  type: \"ConnectionString\";\n  /** The connection string to use for authentication. */\n  connectionString: string;\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using an Elasticsearch key and key ID pair. */\nexport interface OnYourDataKeyAndKeyIdAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of Elasticsearch key and key ID pair. */\n  type: \"KeyAndKeyId\";\n  /** The key to use for authentication. */\n  key: string;\n  /** The key ID to use for authentication. */\n  keyId: string;\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using a system-assigned managed identity. */\nexport interface OnYourDataSystemAssignedManagedIdentityAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of system-assigned managed identity. */\n  type: \"SystemAssignedManagedIdentity\";\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using a user-assigned managed identity. */\nexport interface OnYourDataUserAssignedManagedIdentityAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of user-assigned managed identity. */\n  type: \"UserAssignedManagedIdentity\";\n  /** The resource ID of the user-assigned managed identity to use for authentication. */\n  managedIdentityResourceId: string;\n}\n\n/** Optional settings to control how fields are processed when using a configured Azure Cognitive Search resource. */\nexport interface AzureCognitiveSearchIndexFieldMappingOptions {\n  /** The name of the index field to use as a title. */\n  titleField?: string;\n  /** The name of the index field to use as a URL. */\n  urlField?: string;\n  /** The name of the index field to use as a filepath. */\n  filepathField?: string;\n  /** The names of index fields that should be treated as content. */\n  contentFields?: string[];\n  /** The separator pattern that content fields should use. */\n  contentFieldsSeparator?: string;\n  /** The names of fields that represent vector data. */\n  vectorFields?: string[];\n  /** The names of fields that represent image vector data. */\n  imageVectorFields?: string[];\n}\n\n/** An abstract representation of a vectorization source for Azure OpenAI On Your Data with vector search. */\nexport interface OnYourDataVectorizationSourceParent {\n  type: string;\n}\n\n/**\n * The details of a a vectorization source, used by Azure OpenAI On Your Data when applying vector search, that is based\n * on a public Azure OpenAI endpoint call for embeddings.\n */\nexport interface OnYourDataEndpointVectorizationSource extends OnYourDataVectorizationSourceParent {\n  /** The type of vectorization source to use. Always 'Endpoint' for this type. */\n  type: \"Endpoint\";\n  /** Specifies the resource endpoint URL from which embeddings should be retrieved. It should be in the format of https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/embeddings. The api-version query parameter is not allowed. */\n  endpoint: string;\n  /** Specifies the authentication options to use when retrieving embeddings from the specified endpoint. */\n  authentication: OnYourDataAuthenticationOptions;\n}\n\n/**\n * The details of a a vectorization source, used by Azure OpenAI On Your Data when applying vector search, that is based\n * on an internal embeddings model deployment name in the same Azure OpenAI resource.\n */\nexport interface OnYourDataDeploymentNameVectorizationSource\n  extends OnYourDataVectorizationSourceParent {\n  /** The type of vectorization source to use. Always 'DeploymentName' for this type. */\n  type: \"DeploymentName\";\n  /** The embedding model deployment name within the same Azure OpenAI resource. This enables you to use vector search without Azure OpenAI api-key and without Azure OpenAI public network access. */\n  deploymentName: string;\n}\n\n/**\n * The details of a a vectorization source, used by Azure OpenAI On Your Data when applying vector search, that is based\n * on a search service model ID. Currently only supported by Elasticsearch®.\n */\nexport interface OnYourDataModelIdVectorizationSource extends OnYourDataVectorizationSourceParent {\n  /** The type of vectorization source to use. Always 'ModelId' for this type. */\n  type: \"ModelId\";\n  /** The embedding model ID build inside the search service. Currently only supported by Elasticsearch®. */\n  modelId: string;\n}\n\n/**\n * A specific representation of configurable options for Azure Machine Learning vector index when using it as an Azure\n * OpenAI chat extension.\n */\nexport interface AzureMachineLearningIndexChatExtensionConfiguration\n  extends AzureChatExtensionConfigurationParent {\n  /**\n   * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its\n   * default value for Azure Machine Learning vector index.\n   */\n  type: \"AzureMLIndex\";\n  /** The parameters for the Azure Machine Learning vector index chat extension. */\n  parameters: AzureMachineLearningIndexChatExtensionParameters;\n}\n\n/** Parameters for the Azure Machine Learning vector index chat extension. */\nexport interface AzureMachineLearningIndexChatExtensionParameters {\n  /**\n   * The authentication method to use when accessing the defined data source.\n   * Each data source type supports a specific set of available authentication methods; please see the documentation of\n   * the data source for supported mechanisms.\n   * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)\n   * authentication.\n   */\n  authentication?: OnYourDataAuthenticationOptions;\n  /** The configured top number of documents to feature for the configured query. */\n  topNDocuments?: number;\n  /** Whether queries should be restricted to use of indexed data. */\n  inScope?: boolean;\n  /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */\n  strictness?: number;\n  /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */\n  roleInformation?: string;\n  /** The resource ID of the Azure Machine Learning project. */\n  projectResourceId: string;\n  /** The Azure Machine Learning vector index name. */\n  name: string;\n  /** The version of the Azure Machine Learning vector index. */\n  version: string;\n  /** Search filter. Only supported if the Azure Machine Learning vector index is of type AzureSearch. */\n  filter?: string;\n}\n\n/**\n * A specific representation of configurable options for Elasticsearch when using it as an Azure OpenAI chat\n * extension.\n */\nexport interface AzureCosmosDBChatExtensionConfiguration\n  extends AzureChatExtensionConfigurationParent {\n  /**\n   * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its\n   * default value for Azure Cosmos DB.\n   */\n  type: \"AzureCosmosDB\";\n  /** The parameters to use when configuring Azure OpenAI CosmosDB chat extensions. */\n  parameters: AzureCosmosDBChatExtensionParameters;\n}\n\n/**\n * Parameters to use when configuring Azure OpenAI On Your Data chat extensions when using Azure Cosmos DB for\n * MongoDB vCore.\n */\nexport interface AzureCosmosDBChatExtensionParameters {\n  /**\n   * The authentication method to use when accessing the defined data source.\n   * Each data source type supports a specific set of available authentication methods; please see the documentation of\n   * the data source for supported mechanisms.\n   * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)\n   * authentication.\n   */\n  authentication?: OnYourDataAuthenticationOptions;\n  /** The configured top number of documents to feature for the configured query. */\n  topNDocuments?: number;\n  /** Whether queries should be restricted to use of indexed data. */\n  inScope?: boolean;\n  /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */\n  strictness?: number;\n  /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */\n  roleInformation?: string;\n  /** The MongoDB vCore database name to use with Azure Cosmos DB. */\n  databaseName: string;\n  /** The name of the Azure Cosmos DB resource container. */\n  containerName: string;\n  /** The MongoDB vCore index name to use with Azure Cosmos DB. */\n  indexName: string;\n  /** Customized field mapping behavior to use when interacting with the search index. */\n  fieldsMapping: AzureCosmosDBFieldMappingOptions;\n  /** The embedding dependency for vector search. */\n  embeddingDependency?: OnYourDataVectorizationSource;\n}\n\n/** Optional settings to control how fields are processed when using a configured Azure Cosmos DB resource. */\nexport interface AzureCosmosDBFieldMappingOptions {\n  /** The names of fields that represent vector data. */\n  vectorFields: string[];\n}\n\n/**\n * A specific representation of configurable options for Elasticsearch when using it as an Azure OpenAI chat\n * extension.\n */\nexport interface ElasticsearchChatExtensionConfiguration\n  extends AzureChatExtensionConfigurationParent {\n  /**\n   * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its\n   * default value for Elasticsearch®.\n   */\n  type: \"Elasticsearch\";\n  /** The parameters to use when configuring Elasticsearch®. */\n  parameters: ElasticsearchChatExtensionParameters;\n}\n\n/** Parameters to use when configuring Elasticsearch® as an Azure OpenAI chat extension. */\nexport interface ElasticsearchChatExtensionParameters {\n  /**\n   * The authentication method to use when accessing the defined data source.\n   * Each data source type supports a specific set of available authentication methods; please see the documentation of\n   * the data source for supported mechanisms.\n   * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)\n   * authentication.\n   */\n  authentication?: OnYourDataAuthenticationOptions;\n  /** The configured top number of documents to feature for the configured query. */\n  topNDocuments?: number;\n  /** Whether queries should be restricted to use of indexed data. */\n  inScope?: boolean;\n  /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */\n  strictness?: number;\n  /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */\n  roleInformation?: string;\n  /** The endpoint of Elasticsearch®. */\n  endpoint: string;\n  /** The index name of Elasticsearch®. */\n  indexName: string;\n  /** The index field mapping options of Elasticsearch®. */\n  fieldsMapping?: ElasticsearchIndexFieldMappingOptions;\n  /**\n   * The query type of Elasticsearch®.\n   *\n   * Possible values: simple, vector\n   */\n  queryType?: string;\n  /** The embedding dependency for vector search. */\n  embeddingDependency?: OnYourDataVectorizationSource;\n}\n\n/** Optional settings to control how fields are processed when using a configured Elasticsearch® resource. */\nexport interface ElasticsearchIndexFieldMappingOptions {\n  /** The name of the index field to use as a title. */\n  titleField?: string;\n  /** The name of the index field to use as a URL. */\n  urlField?: string;\n  /** The name of the index field to use as a filepath. */\n  filepathField?: string;\n  /** The names of index fields that should be treated as content. */\n  contentFields?: string[];\n  /** The separator pattern that content fields should use. */\n  contentFieldsSeparator?: string;\n  /** The names of fields that represent vector data. */\n  vectorFields?: string[];\n}\n\n/**\n * A specific representation of configurable options for Elasticsearch when using it as an Azure OpenAI chat\n * extension.\n */\nexport interface PineconeChatExtensionConfiguration extends AzureChatExtensionConfigurationParent {\n  /**\n   * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its\n   * default value for Pinecone.\n   */\n  type: \"Pinecone\";\n  /** The parameters to use when configuring Azure OpenAI chat extensions. */\n  parameters: PineconeChatExtensionParameters;\n}\n\n/** Parameters for configuring Azure OpenAI Pinecone chat extensions. */\nexport interface PineconeChatExtensionParameters {\n  /**\n   * The authentication method to use when accessing the defined data source.\n   * Each data source type supports a specific set of available authentication methods; please see the documentation of\n   * the data source for supported mechanisms.\n   * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)\n   * authentication.\n   */\n  authentication?: OnYourDataAuthenticationOptions;\n  /** The configured top number of documents to feature for the configured query. */\n  topNDocuments?: number;\n  /** Whether queries should be restricted to use of indexed data. */\n  inScope?: boolean;\n  /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */\n  strictness?: number;\n  /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */\n  roleInformation?: string;\n  /** The environment name of Pinecone. */\n  environment: string;\n  /** The name of the Pinecone database index. */\n  indexName: string;\n  /** Customized field mapping behavior to use when interacting with the search index. */\n  fieldsMapping: PineconeFieldMappingOptions;\n  /** The embedding dependency for vector search. */\n  embeddingDependency?: OnYourDataVectorizationSource;\n}\n\n/** Optional settings to control how fields are processed when using a configured Pinecone resource. */\nexport interface PineconeFieldMappingOptions {\n  /** The name of the index field to use as a title. */\n  titleField?: string;\n  /** The name of the index field to use as a URL. */\n  urlField?: string;\n  /** The name of the index field to use as a filepath. */\n  filepathField?: string;\n  /** The names of index fields that should be treated as content. */\n  contentFields?: string[];\n  /** The separator pattern that content fields should use. */\n  contentFieldsSeparator?: string;\n  /** The names of fields that represent vector data. */\n  vectorFields?: string[];\n  /** The names of fields that represent image vector data. */\n  imageVectorFields?: string[];\n}\n\n/** A representation of the available Azure OpenAI enhancement configurations. */\nexport interface AzureChatEnhancementConfiguration {\n  /** A representation of the available options for the Azure OpenAI grounding enhancement. */\n  grounding?: AzureChatGroundingEnhancementConfiguration;\n  /** A representation of the available options for the Azure OpenAI optical character recognition (OCR) enhancement. */\n  ocr?: AzureChatOCREnhancementConfiguration;\n}\n\n/** A representation of the available options for the Azure OpenAI grounding enhancement. */\nexport interface AzureChatGroundingEnhancementConfiguration {\n  /** Specifies whether the enhancement is enabled. */\n  enabled: boolean;\n}\n\n/** A representation of the available options for the Azure OpenAI optical character recognition (OCR) enhancement. */\nexport interface AzureChatOCREnhancementConfiguration {\n  /** Specifies whether the enhancement is enabled. */\n  enabled: boolean;\n}\n\n/** An abstract representation of a tool that can be used by the model to improve a chat completions response. */\nexport interface ChatCompletionsToolDefinitionParent {\n  type: string;\n}\n\n/** The definition information for a chat completions function tool that can call a function in response to a tool call. */\nexport interface ChatCompletionsFunctionToolDefinition extends ChatCompletionsToolDefinitionParent {\n  /** The object name, which is always 'function'. */\n  type: \"function\";\n  /** The function definition details for the function tool. */\n  function: FunctionDefinition;\n}\n\n/** An abstract representation of an explicit, named tool selection to use for a chat completions request. */\nexport interface ChatCompletionsNamedToolSelectionParent {\n  type: string;\n}\n\n/** A tool selection of a specific, named function tool that will limit chat completions to using the named function. */\nexport interface ChatCompletionsNamedFunctionToolSelection\n  extends ChatCompletionsNamedToolSelectionParent {\n  /** The object type, which is always 'function'. */\n  type: \"function\";\n  /** Specifies a tool the model should use. Used to force the model to call a specific function. */\n  function: {\n    /** The name of the function that should be called. */\n    name: string;\n  };\n}\n\n/** Represents the request data used to generate images. */\nexport interface ImageGenerationOptions {\n  /**\n   * The model name or Azure OpenAI model deployment name to use for image generation. If not specified, dall-e-2 will be\n   * inferred as a default.\n   */\n  model?: string;\n  /** A description of the desired images. */\n  prompt: string;\n  /**\n   * The number of images to generate.\n   * Dall-e-2 models support values between 1 and 10.\n   * Dall-e-3 models only support a value of 1.\n   */\n  n?: number;\n  /**\n   * The desired dimensions for generated images.\n   * Dall-e-2 models support 256x256, 512x512, or 1024x1024.\n   * Dall-e-3 models support 1024x1024, 1792x1024, or 1024x1792.\n   *\n   * Possible values: 256x256, 512x512, 1024x1024, 1792x1024, 1024x1792\n   */\n  size?: string;\n  /**\n   * The format in which image generation response items should be presented.\n   *\n   * Possible values: url, b64_json\n   */\n  response_format?: string;\n  /**\n   * The desired image generation quality level to use.\n   * Only configurable with dall-e-3 models.\n   *\n   * Possible values: standard, hd\n   */\n  quality?: string;\n  /**\n   * The desired image generation style to use.\n   * Only configurable with dall-e-3 models.\n   *\n   * Possible values: natural, vivid\n   */\n  style?: string;\n  /** A unique identifier representing your end-user, which can help to monitor and detect abuse. */\n  user?: string;\n}\n\n/**\n * The configuration information for an embeddings request.\n * Embeddings measure the relatedness of text strings and are commonly used for search, clustering,\n * recommendations, and other similar scenarios.\n */\nexport interface EmbeddingsOptions {\n  /**\n   * An identifier for the caller or end user of the operation. This may be used for tracking\n   * or rate-limiting purposes.\n   */\n  user?: string;\n  /**\n   * The model name to provide as part of this embeddings request.\n   * Not applicable to Azure OpenAI, where deployment information should be included in the Azure\n   * resource URI that's connected to.\n   */\n  model?: string;\n  /**\n   * Input texts to get embeddings for, encoded as a an array of strings.\n   * Each input must not exceed 2048 tokens in length.\n   *\n   * Unless you are embedding code, we suggest replacing newlines (\\\\n) in your input with a single space,\n   * as we have observed inferior results when newlines are present.\n   */\n  input: string[];\n}\n\n/** An abstract representation of a chat message as provided in a request. */\nexport type ChatRequestMessage =\n  | ChatRequestSystemMessage\n  | ChatRequestUserMessage\n  | ChatRequestAssistantMessage\n  | ChatRequestToolMessage\n  | ChatRequestFunctionMessage;\n/** An abstract representation of a structured content item within a chat message. */\nexport type ChatMessageContentItem = ChatMessageTextContentItem | ChatMessageImageContentItem;\n/**\n * An abstract representation of a tool call that must be resolved in a subsequent request to perform the requested\n * chat completion.\n */\nexport type ChatCompletionsToolCall = ChatCompletionsFunctionToolCall;\n/**\n *   A representation of configuration data for a single Azure OpenAI chat extension. This will be used by a chat\n *   completions request that should use Azure OpenAI chat extensions to augment the response behavior.\n *   The use of this configuration is compatible only with Azure OpenAI.\n */\nexport type AzureChatExtensionConfiguration =\n  | AzureCognitiveSearchChatExtensionConfiguration\n  | AzureMachineLearningIndexChatExtensionConfiguration\n  | AzureCosmosDBChatExtensionConfiguration\n  | ElasticsearchChatExtensionConfiguration\n  | PineconeChatExtensionConfiguration;\n/** The authentication options for Azure OpenAI On Your Data. */\nexport type OnYourDataAuthenticationOptions =\n  | OnYourDataApiKeyAuthenticationOptions\n  | OnYourDataConnectionStringAuthenticationOptions\n  | OnYourDataKeyAndKeyIdAuthenticationOptions\n  | OnYourDataSystemAssignedManagedIdentityAuthenticationOptions\n  | OnYourDataUserAssignedManagedIdentityAuthenticationOptions;\n/** An abstract representation of a vectorization source for Azure OpenAI On Your Data with vector search. */\nexport type OnYourDataVectorizationSource =\n  | OnYourDataEndpointVectorizationSource\n  | OnYourDataDeploymentNameVectorizationSource\n  | OnYourDataModelIdVectorizationSource;\n/** An abstract representation of a tool that can be used by the model to improve a chat completions response. */\nexport type ChatCompletionsToolDefinition = ChatCompletionsFunctionToolDefinition;\n/** An abstract representation of an explicit, named tool selection to use for a chat completions request. */\nexport type ChatCompletionsNamedToolSelection = ChatCompletionsNamedFunctionToolSelection;\n\n/** The standard Chat Completions response format that can freely generate text and is not guaranteed to produce response\ncontent that adheres to a specific schema. */\nexport interface ChatCompletionsTextResponseFormat {\n  /** The object type, which is always 'text' for this object. */\n  type: \"text\";\n}\n/** A response format for Chat Completions that restricts responses to emitting valid JSON objects.\n */\nexport interface ChatCompletionsJsonResponseFormat {\n  /** The object type, which is always 'json_object' for this object. */\n  type: \"json_object\";\n}\n\n/** The valid response formats Chat Completions can provide. Used to enable JSON mode. */\nexport type ChatCompletionsResponseFormat =\n  | ChatCompletionsTextResponseFormat\n  | ChatCompletionsJsonResponseFormat;\n"]}